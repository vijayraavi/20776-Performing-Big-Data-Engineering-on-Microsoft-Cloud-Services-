# Module 6: Implementing Custom Operations and Monitoring Performance in Azure Data Lake Analytics

# Lab: Implementing custom operations and monitoring performance in Azure Data Lake Analytics

## Exercise 1: Use a custom extractor, read JSON file data, and use a custom outputter to XML

#### Task 1: Deploy and test a JSON extractor
1.  On 20776A-MIA-DEV, on the Start menu, type **Visual Studio 2017**, and then press Enter.
2.  In Visual Studio, click **Open Project / Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab06\\Exercise1\\Starter\\CustomFunctions** folder, click **CustomFunctions.sln**, and then click **Open**.
4.  In Solution Explorer, double-click **JsonExtractor.cs**.
5.  In the code editor window, browse the code for the JsonExtractor, and note the following points:
    1.  The JsonExtractor class extends the IExtractor base class.
    2.  The Extract function is an override; this override uses functions in the Newtonsoft JSON library to read the JSON data from the input line (this contains a single line from the input file).
    3.  After the JSON data has been retrieved, and the fields in the input line extracted into an output row, this output row is returned to USQL.
    4.  The class is tagged with the [SqlUserDefinedExtractor(AtomicFileProcessing = true)] attribute; this is because the input data consists of a single object (a JSON array), and so its contents cannot be read by separate vertices in parallel.
    5.  The constructor specifies the name of the array to parse in the input; this is because there could possibly be multiple arrays in the same JSON file.
    6.  This class contains many other supporting functions that do all the parsing, and so on; you should ignore these functions for the purposes of this exercise.
6.  On the **Build** menu, click **Build Solution**.
7.  In Solution Explorer, right-click **CustomExtractors**, and then click **Register Assembly**.
8.  In the **Assembly Registration** dialog box, set the **ADLA Account** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
9.  Leave the **Database** set to **master**.
10. Select the **Replace assembly if it already exists** check box.
11. Expand **Managed Dependencies**, select the **Newtonsoft.Json** check box (this is the assembly containing the JSON Newtonsoft library), and then click **Submit**.
12. If the **Registration Script** dialog box appears, click **Yes**.
13. On the Start menu, type **Wordpad**, and then press Enter.
14. In Wordpad, on the **File** menu, click **Open**.
15. In the **Open** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise1**, click **All Documents (\*.\*)**, click **SpeedData.json**, and then click **Open**.
16. Note that this file contains speed camera data formatted as a JSON array; there are more than a million records in the file, which is why you are not using Notepad to view it, because it would take too long to load.
17. Close Wordpad.
18. Switch to the Azure portal.
19. Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data Explorer**.
20. In Data Explorer, in the default (root) folder, click **Upload**.
21. In the **Upload files** blade, click the **file** button.
22. In the **Choose File to Upload** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise1**, click **SpeedData.json**, and then click **Open**.
23. On the **Upload files** blade, click **Add selected files**.
24. After the file has uploaded, close the **Upload files** blade.
25. On the Start menu, type **Visual Studio 2017**, and then press Enter, to open a second instance of Visual Studio 2017.
26. In Visual Studio, on the **File** menu, point to **New**, and then click **Project**.
27. In the **New Project** dialog box, in the **Templates** list, expand **Azure Data Lake**, and then click **U-SQL**.
28. In the **New Project** dialog box, in the **Name** box, type **JsonExtractorTest**, and then click **OK**.
29. In the **Script.usql** pane, type the following code (you copy this code from **E:\\Labfiles\\Lab06\\Exercise1\\JsonExtractorTest1.usql**):

	```
	// Assembly references for the JSON extractor and Newtonsoft assembly (required by the extractor) stored in the catalog

    REFERENCE ASSEMBLY [Newtonsoft.Json];
	REFERENCE ASSEMBLY [CustomExtractors];

    // Use the Json extractor to read the data from the SpeedData.json file. The fields of interest in the file are CameraID string, SpeedLimit int, Speed int, VehicleRegistration string, Date string (there is also the Month field that you can ignore for this lab):

    @speedData =
	EXTRACT CameraID string, SpeedLimit int, Speed int, VehicleRegistration string, Date string
	FROM "/SpeedData.json"
	USING new CustomExtractors.JsonExtractor();

    // Save the data to a CSV file named ConvertedSpeedData.csv:

    OUTPUT @speedData
	TO "/ConvertedSpeedData.csv"
	USING Outputters.Csv(quoting: false, outputHeader: true);
	```
30.  In the **Script.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
31.  When the job has completed, close the **Job View** pane.
32.  Switch to the Azure portal.
33.  In Data Explorer, click **ConvertedSpeedData.csv**, to view the extracted data.
34.  Close the **File Preview** blade.

#### Task 2: Deploy and test an XML outputter
1.  Switch to the instance of Visual Studio 2017 that has the **CustomFunctions** solution open.
2.  In Solution Explorer, expand **CustomOutputters**, and then double-click **XmlOutputter.cs**.
3.  In the code editor window, note the following points:
    1.  The SimpleXMLOutputter class extends the IOutputter base class.
    2.  The Output function is an override that formats a line of data as a simple XML object; the object tag to use is specified by the constructor.
    3.  The class is tagged with the [SqlUserDefinedOutputter(AtomicFileProcessing = false)] attribute; each line of output is a separate XML document, so the output is generated by using multiple vertices running in parallel.
    4.  The Close method flushes and closes the output stream.
4.  On the **Build** menu, click **Rebuild Solution**.
5.  In Solution Explorer, right-click **CustomOutputters**, and then click **Register Assembly**.
6.  In the **Assembly Registration** dialog box, set the **ADLA Account** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
7.  Leave the **Database** set to **master**.
8.  Select the **Replace assembly if it already exists** check box, and then click **Submit**.
9.  Switch to the instance of Visual Studio 2017 that has the **JsonExtractorTest** solution open.
10. In the **Script.usql** script, add the following statements to the end of the script (you copy this code from **E:\\Labfiles\\Lab06\\Exercise1\\JsonExtractorTest2.usql**):

	```
	// Assembly reference for the XML outputter

    REFERENCE ASSEMBLY [CustomOutputters];

    // Modify the statement that outputs the data to use the XmlOutputter. Save the data as ConvertedSpeedData.xml

    OUTPUT @speedData
	TO "/ConvertedSpeedData.xml"
	USING new CustomOutputters.XmlOutputter();
	```
11.  In the **Script.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
12.  When the job has completed, close the **Job View** pane.
13.  Switch to the Azure portal.
14.  In Data Explorer, next to **ConvertedSpeedData.xml**, click the ellipsis (**...**), and then click **Download**.
15.  On the **Download** blade, click **Start Download now**.
16.  In the Internet Explorer message box, click the **Save** drop-down arrow, and then click **Save as**.
17.  In the **Save As** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise1**, and then click **Save**.
18.  In the Internet Explorer message box, click **Open folder**.
19.  In File Explorer, double-click **ConvertedSpeedData.xml**.
20. In the **How do you want to open this file?** dialog box, click **Microsoft Visual Studio 2017**, and then click **OK**.
21. Confirm that the file contains the speed camera data formatted as XML.
22. Close the instance of Visual Studio that has the open **ConvertedSpeedData.xml** window.
23. Switch to the Azure portal.
24. Close the **Download** blade.
25. **Note**: If you try to view the data using Data Explorer, the data will not be displayed correctly because Data Explorer does not understand the XML format.

>**Result**: At the end of this exercise, you will have deployed and tested a custom extractor, and deployed and tested a custom outputter.

## Exercise 2: Optimize a table in the ADLA catalog

#### Task 1: Create the SpeedData table in the catalog
1.  Switch to the remaining instance of Visual Studio.
2.  On the **File** menu, point to **New**, and then click **Project**.
3.  In the **New Project** dialog box, in the **Templates** list, expand **Azure Data Lake**, and then click **U-SQL**.
4.  In the **New Project** dialog box, in the **Name** box, type **SpeedCameraAnalytics2**, and then click **OK**.
5.  In Solution Explorer, right-click **Script.usql**, click **Rename**, type **CreateTable**, and then press Enter.
6.  In CreateTable.usql, add the following statement to create a new database called VehicleData (if it doesn't already exist); you copy the code for steps 6 to 9 from **E:\\Labfiles\\Lab06\\Exercise2\\CreateTable1.usql**:

	```
	CREATE DATABASE IF NOT EXISTS VehicleData;
	```
7.  In CreateTable.usql, add the following statements to create a table for holding speed camera information, and to index the data by camera id, and hash the data by the vehicle registration:

	```
	DROP TABLE IF EXISTS VehicleData.dbo.SpeedCameraData;
	CREATE TABLE VehicleData.dbo.SpeedCameraData(
	CameraID string,
	VehicleRegistration string,
	Speed int,
	SpeedLimit int,
	Date DateTime,
	INDEX cameraidx
	CLUSTERED(CameraID ASC)
	DISTRIBUTED BY
	HASH(VehicleRegistration)
	);
	```
Note that the rationale behind this hashing strategy is to distribute the load across the database, to try and avoid hotspots in the data. The index is intended to support fast lookup of speed data by camera ID.

8.  In CreateTable.usql, add the following statements to reference the assemblies required by the JSON extractor:

	```
	REFERENCE ASSEMBLY [Newtonsoft.Json];
	REFERENCE ASSEMBLY [CustomExtractors];
	```
9.  In CreateTable.usql, add the following statements to read the data from the SpeedData.json file:

	```
	@speedData =
	EXTRACT CameraID string, SpeedLimit int, Speed int, VehicleRegistration string, Date string
	FROM "/SpeedData.json"
	USING new CustomExtractors.JsonExtractor();
	```
10. The dates in the JSON input are strings in the format "dd/mm/yy hh24:mi"; therefore, you need to add a user-defined function to convert a string in this format into a DateTime object.
11. In Solution Explorer, expand **CreateTable.usql**, and then double-click **CreateTable.usql.cs**, to edit the code-behind C\# file.
12. Replace the entire contents of this file with the following code (you copy this code from **E:\\Labfiles\\Lab06\\Exercise2\\CreateTable.usql.cs**):

	```
	using System;
	namespace SpeedCameraAnalytics2
	{
	public class UDFs
	{
	public static DateTime ConvertStringToDate(string date)
	{
	// The input string is in the form "dd/mm/yyyy hh24:mi"
	char[] delimiters = { ' ', '/', ':' };
	string[] dateBits = date.Split(delimiters);
	int day = Convert.ToInt32(dateBits[0]);
	int month = Convert.ToInt32(dateBits[1]);
	int year = Convert.ToInt32(dateBits[2]);
	int hour = Convert.ToInt32(dateBits[3]);
	int minute = Convert.ToInt32(dateBits[4]);
	DateTime dt = new DateTime(year, month, day, hour, minute, 0);
	return dt;
	}
	}
	}
	```
This code defines a function called ConvertStringToDate; this function parses the input string, and uses it to construct a DateTime object.

13. In Solution Explorer, double-click **CreateTable.usql**, and then add the following statement to the end of the existing code (you copy this code from **E:\\Labfiles\\Lab06\\Exercise2\\CreateTable2.usql**):

	```
	INSERT INTO VehicleData.dbo.SpeedCameraData (CameraID, VehicleRegistration, Speed, SpeedLimit, Date)
	SELECT CameraID, VehicleRegistration, Speed, SpeedLimit, SpeedCameraAnalytics2.UDFs.ConvertStringToDate(Date) AS Date
	FROM @speedData;
	```
This statement inserts the data read by using the JSON extractor into the SpeedCameraData table; notice that this statement calls the ConvertStringToDate function for each row of input.

14. In the **CreateTable.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
15. Switch to the Azure portal.
16. Click **All resources**, and then click **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
17. On the **speedsdla&lt;_your name_&gt;&lt;_date_&gt;** blade, under **DATA LAKE ANALYTICS**, click **Job Management**.
18. On the **speedsdla&lt;_your name_&gt;&lt;_date_&gt; - Job Management** blade, click the topmost job (it will probably be marked with a status of Preparing or Queued, but if you have not been too quick to get to this step, it could be marked as Running).
19. Wait while the job runs; when it has finished, with a status of Succeeded, at the bottom of the graph, click the **SpeedCameraData** table.
20. On the **dbo.SpeedCameraData** blade, click **Query Table**.
21. On the **New U-SQL Job** blade, click **Submit Job**.
22. Wait while the query job runs; when it has completed, on the **Output** tab, click the **VehicleData.dbo.SpeedCameraData.tsv** file.
23. Browse the data; you should see rows for Camera 0 (the browser only shows the first few rows), and the data is not in any specific order.

#### Task 2: Create a U-SQL job that analyzes data for a specific camera
1.  Switch to Visual Studio.
2.  Close any existing **Job View** panes.
3.  In Solution Explorer, right-click **SpeedCameraAnalytics2**, point to **Add**, and then click **New Item**.
4.  In the **Add New Item - SpeedCameraAnalytics2** dialog box, click **U-SQL Script**, in the **Name** box, type **AnalyzeSpeedsByCamera.usql**, and then click **Add**.
5.  In AnalyzeSpeedsByCamera.usql, add the following statements to perform a query and generate a summary for Camera 121 (you copy this code from **E:\\Labfiles\\Lab06\\Exercise2\\AnalyzeSpeedsByCamera.usql**):

	```
	// Find the statistics for a specific camera

    DECLARE @camera = "Camera 121";

    @speedSummary =
	SELECT CameraID,
	MAX(SpeedLimit) AS SpeedLimit,
	COUNT(*) AS NumberOfObservations,
	MIN(Speed) AS Lowest,
	MAX(Speed) AS Highest,
	AVG(Speed) AS Average
	FROM VehicleData.dbo.SpeedCameraData
	WHERE CameraID == @camera
	GROUP BY CameraID;

    // Save the results to SpeedSummary.csv::

    OUTPUT @speedSummary
	TO "/SpeedSummary.csv"
	USING Outputters.Csv(outputHeader: true, quoting: false);
	```
6.  In the **AnalyzeSpeedsByCamera.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
7.  In the **Job View** pane, position the cursor over the **SV1 Extract** stage; this stage should report that it is running 10 vertices and reading 40 MB of data, and it outputs 10 rows (there is one row of summary data generated by each vertex). These 10 rows are passed to the SV2 Aggregate stage, which combines them together to produce a single row.
8.  In the **Job View** pane, double-click **SpeedSummary.csv** to see the following results:

	```
	CameraID: Camera 121
	SpeedLimit: 30
	Number of Observations: 6057
	Lowest: 0
	Highest: 116
	Average: 7
	```
9.  Close the **File Preview** pane.
10.  In the **Job View** pane, click **Load Profile**.
11.  Right-click **SV1 Extract**, and then click **Show Vertex Execution View**. The job was run with the default number of AUs (5), and you can see how the job was performed, with five vertices running first, and the next five running as the first five completed. The vertex for the Aggregate stage ran when the vertices for the Extract stage had all finished.
12.  In the upper left of the **Vertex Execution View**, click the left arrow to return to the **Job View** pane.
13.  Right-click **SV1 Extract**, and then click **Show Stage Scatter View**.
14.  In the **Stage Scatter Chart**, under **Legend**, clear the **Output** check box, to focus on the volume of data and time spent performing input. Each vertex read approximately the same amount of data (about 4 MB), but the time spent is grouped into two distinct sets. This is because the second five vertices had to wait for a vertex to become available while the first five were running.
15.  In the upper left of the **Stage Scatter Chart**, click the left arrow to return to the **Job View** pane.
16.  Right-click **SV1 Extract**, and then click **Show Vertex Operator View**.
17.  This view shows the logical data flow in terms of fields and numbers of rows. The extractor read 6,057 rows but, because the data is spread across the database, it created a separate vertex to handle the rows from each chunk of data that it read. Each vertex (Process\_1 in the graph) performs the aggregation over the data from that chunk, and sends the results to the second stage (Process\_2). Process\_2 does the final aggregation and sends the results to the output.
18. Close the **View** **Vertex** and **Job View** panes.

#### Task 3: Redistribute the data to optimize data retrieval

One way to optimize the data would be to partition it by camera ID. However, there are currently 500 cameras in this dataset, so this process would involve creating 500 partitions, which is probably not feasible (note that U-SQL only supports partitioning by ID, and does not support user-defined partitioning functions that are available in SQL Server). Another solution is to distribute the data by Camera ID rather than VehicleRegistration. In this way, the observations for a specific camera should be grouped close together in the database, and will hopefully reduce the amount of I/O that the analysis needs to perform.
1.  In Visual Studio, click the **CreateTable.usql** pane.
2.  In the **CreateTable.usql** script, edit the CREATE TABLE command to distribute data by hashing the CameraID; replace the existing DISTRIBUTED BY HASH(VehicleRegistration) string with the following:

	```
	DISTRIBUTED BY
	HASH(CameraID)
	```
3.  In the **CreateTable.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
4.  Wait until the script has completed successfully before continuing with this exercise.
5.  Click the **AnalyzeSpeedsByCamera.usql** pane.
6.  In the **AnalyzeSpeedsByCamera.usql** pane, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
7.  When the script has completed, examine the graph in the Job View pane, and position the cursor over the **SV1 Extract** stage. You should now see that the job comprised a single stage that required only a single vertex. This stage read 3.93 MB of data (rather than 10 stages each reading nearly 4 MB each) and, because the data was all available in the same "chunk", it could be processed and aggregated in a single stage.
8.  Double-click the **SpeedSummary.csv** file and verify that the results are the same as before:

	```
	CameraID: Camera 121
	SpeedLimit: 30
	Number of Observations: 6057
	Lowest: 0
	Highest: 116
	Average: 7
	```
9.  Close Visual Studio, saving any changes.

>**Result**: At the end of this exercise, you will have created a table in the ADLA catalog, analyzed data in this table, and redistributed data in the catalog for optimal retrieval.

## Exercise 3: Implement a custom processor in ADLA

#### Task 1: Preparation: upload stolen vehicle data to ADLS (using AzCopy and Adlcopy)
1.  In the Azure portal, click **+ New**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
2.  On the **Create storage account** blade, in the **Name** box, type **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**.
3.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
4.  In the **Location** list, select the same location as you used for the data warehouse in Exercise 1.
5.  Leave all other details at their defaults, and click **Create**.
6.  Wait until the storage account has been successfully created before continuing with the exercise.
7.  Click **All resources**, and then click **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**.
8.  On the **vehicledata&lt;_your name_&gt;&lt;_date_&gt;** blade, under **BLOB SERVICE**, click **Containers**, and then click **+ Container**.
9.  In the **New container** dialog box, in the **Name** box, type **stolen**, and then click **OK**.
10. On the **vehicledata&lt;_your name_&gt;&lt;_date_&gt; -** **Containers** blade, under **SETTINGS**, click **Access keys**.
11. Next to **key1**, click the **Click to copy** button, to copy the key to the clipboard.
12. Right-click the Start button, and then click **Command Prompt (Admin)**.
13. In the **User Account Control** dialog box, click **Yes**.
14. At the command prompt, type the following command, and then press Enter:

	```
	dir E:\Labfiles\Lab06\Exercise3\StolenVehicles /s
	```
15.  Note that the **StolenVehicles** folder contains eight years of stolen vehicle data, organized in subfolders by year/month/day; there are 2,914 separate CSV files.
16.  At the command prompt, type the following command (replacing **&lt;storage account name&gt;** with **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**, and replacing **&lt;storage key&gt;** with the key you copied to the clipboard), and then press Enter:

	```
	azcopy /Source:"E:\Labfiles\Lab06\Exercise3\StolenVehicles" /Dest:https://<storage account name>.blob.core.windows.net/stolen /DestKey:<storage key> /S
	```
17.  The copy process might take several minutes to complete; wait until all files have been copied before continuing with the exercise.
18.  On the Start menu, type **Visual Studio 2017**, and then press Enter.
19.  In Visual Studio, on the **View** menu, click **Cloud Explorer**.
20.  In Cloud Explorer, if you do not have your Azure Learning Pass subscription folder, complete the following steps:
    1.  Click the **Azure** **Account settings** icon, and then click **Add an account**.
    2.  In the **Sign in to your account** dialog box, sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
    3.  In Cloud Explorer, select your Azure Learning Pass subscription, and then click **Apply**.
21.  Under your Azure Learning Pass subscription folder, expand **Storage Accounts**, expand **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**, expand **Blob Containers**, and then double-click **stolen**.
22.  Verify that the files and subfolders have been uploaded.
23.  Close this instance of Visual Studio.
24.  Switch to the Azure portal.
25.  Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data Explorer**.
26. In Data Explorer, click **New Folder**.
27. In the **Create new folder** box, type **Stolen**, and then click **OK**.
28. Switch to the command prompt.
29. At the command prompt, type the following command (replacing **&lt;storage account name&gt;** with **vehicledata&lt;_your name_&gt;&lt;_date_&gt;**, replacing **&lt;Data Lake Store name&gt;** with **adls&lt;_your name_&gt;&lt;_date_&gt;**, and replacing **&lt;storage key&gt;** with the blob store key you copied to the clipboard), and then press Enter:

	```
	adlcopy /source https://<storage account name>.blob.core.windows.net/stolen/ /dest adl://<Data Lake Store name>.azuredatalakestore.net/Stolen/ /sourcekey <storage key>
	```
You copy the preceding command from **E:\\Labfiles\\Lab06\\Exercise3\\AdlCopyCmd.txt**.

30.  If a **Sign in to your account** dialog box appears, sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
31.  **Note**: Depending on the region and the location of the Blob storage account (ideally they should be in the same region, but might not be), AdlCopy will take from two to 20 minutes to copy the data. Ignore the stats that indicate the percentage of files copied—it sits at 0.00 percent until complete then jumps to 100 percent, and might copy the data in three phases (files 1 to 1,000, then files 1,001 to 2,000, and then the remainder).
32.  Switch to the Azure portal.
33.  In Data Explorer, click the **Stolen** folder, and verify that all the files and folders have been copied across.

#### Task 2: Examine and deploy a custom reducer
1.  On the Start menu, type **Visual Studio 2017**, and then press Enter, to open a second instance of Visual Studio 2017.
2.  In Visual Studio, click **Open Project / Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab06\\Exercise3\\Starter\\CustomReducers** folder, click **CustomReducers.sln**, and then click **Open**.
4.  In Solution Explorer, expand **CustomReducers**, and then double-click **StolenVehicleReducer.cs**.
5.  In the code editor window, browse the code for the StolenVehicleReducer; note the following points:
    1.  The ReduceByRecoveredVehicles class extends the IReducer base class.
    2.  The class is tagged with the [SqlUserDefinedReducer(IsRecursive = true)] attribute; you can reduce each group of data in parallel.
    3.  The Reduce function is an override that examines each row of input; the input contains a set of stolen vehicle records (VehicleRegistration, DateStolen, DateRecovered) that will be grouped by registration (you will specify this when you call the reducer from the U-SQL job).
    4.  The Reduce function only outputs rows for vehicles that it considers to be still missing (the most recent record does not have a recovery date).
6.  On the **Build** menu, click **Rebuild Solution**.
7.  In Solution Explorer, right-click **CustomReducers**, and then click **Register Assembly**.
8.  In the **Assembly Registration** dialog box, set the **ADLA** **Account** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**.
9.  Leave the **Database** set to **master**.
10. Select the **Replace assembly if it already exists** check box, and then click **Submit**.
11. When the **Assembly Registration** job has completed, close the **Job View** pane.

#### Task 3: Test the custom reducer
1.  Switch to the instance of Visual Studio 2017 that has the **SpeedCameraAnalytics2** solution open.
2.  In Solution Explorer, right-click **SpeedCameraAnalytics2**, point to **Add**, and then click **New Item**.
3.  In the **Add New Item** dialog box, click **U-SQL Script**, in the **Name** box, type **AnalyzeSpeedsByVehicle.usql**, and then click **Add**.
4.  In AnalyzeSpeedsByVehicle.usql, add the following statements (you copy this code from **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle1.usql**):

	```
	// Assembly references for the reducer:

    REFERENCE ASSEMBLY CustomReducers;

    // Use a CSV extractor to read the stolen vehicle data from the files under the Stolen folder in ADLS file; the fields of interest in the file are VehicleRegistration string, DateStolen string, and DateRecovered string:

    @stolenVehicleHistory =
	EXTRACT VehicleRegistration string,
	DateStolen string,
	DateRecovered string // Can be empty
	FROM "/Stolen/\*}/{*}/{*}/VehicleData.csv"
	USING Extractors.Csv(skipFirstNRows: 1);

    // Call the reducer to reduce the rowset to only those vehicles that are currently marked as stolen; group the data by VehicleRegistration as it is passed to the reducer:

    @stolenVehicles =
	REDUCE @stolenVehicleHistory
	ON VehicleRegistration
	PRODUCE VehicleRegistration string,
	DateStolen DateTime
	USING new CustomReducers.ReduceByRecoveredVehicles();

    // Save the results to StolenVehicleSpeedAnalysis.csv:

    OUTPUT @stolenVehicles
	TO "/StolenVehicleSpeedAnalysis.csv"
	USING Outputters.Csv(quoting : false, outputHeader : true);
	```
5.  In the **AnalyzeSpeedsByVehicle.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
6.  When the job has completed, close the **Job View** pane.
7.  Switch to the Azure portal.
8.  Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data Explorer**.
9.  In Data Explorer, in the lower left of the blade, click the **Next** arrow, and then click **StolenVehicleSpeedAnalysis.csv**. Note that the data is sorted by VehicleRegistration as a by-product of the reduction process.
10.  On the **File Preview** blade, click **Download**.
11.  On the **Download** blade, click **Start Download now**.
12.  In the Internet Explorer message box, click the **Save** drop-down arrow, and then click **Save as**.
13.  In the **Save As** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise3**, and then click **Save**.
14. In the Internet Explorer message box, click **Open folder**.
15. In File Explorer, double-click **StolenVehicleSpeedAnalysis.csv**.
16. In Microsoft Excel, view the data, and note that there are 241,244 records, plus the header.
17. Close Microsoft Excel.
18. Switch to the Azure portal.
19. Close the **Download** and **File Preview** blades.

#### Task 4: Analyze the speed camera data to check for stolen vehicles
1.  Switch to the instance of Visual Studio 2017 that has the **SpeedCameraAnalytics2** solution open.
2.  In AnalyzeSpeedsByVehicle.usql, before the OUTPUT statement, add the following SELECT statement to join the data in the **VehicleData.dbo.SpeedCameraData** table in the catalog with the stolen vehicle data returned by the reducer across the VehicleRegistration column. Count the number of rows for each camera (you copy this code from **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle2.usql**):

	```
	@stolenVehicleAnalysis =
	SELECT C.CameraID,
	COUNT(C.VehicleRegistration) AS NumStolenVehicles
	FROM VehicleData.dbo.SpeedCameraData AS C
	JOIN
	@stolenVehicles AS V
	ON C.VehicleRegistration == V.VehicleRegistration
	GROUP BY C.CameraID;
	```
3.  In AnalyzeSpeedsByVehicle.usql, before the OUTPUT statement, add another SELECT statement that simply finds the total number of vehicles that have passed each camera (you copy this code from **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle3.usql**):

	```
	@vehicleAnalysis =
	SELECT CameraID,
	COUNT(VehicleRegistration) AS NumVehicles
	FROM VehicleData.dbo.SpeedCameraData
	GROUP BY CameraID;
	```
4.  In AnalyzeSpeedsByVehicle.usql, before the OUTPUT statement, join the results of the previous two SELECT statements across the CameraID column, and calculate the percentage of cars passing each camera that are stolen (you copy this code from **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle4.usql**):

	```
	@speedCameraAnalysis =
	SELECT C.CameraID,
	C.NumVehicles,
	V.NumStolenVehicles,
	((double)V.NumStolenVehicles / C.NumVehicles) * 100 AS PercentStolen
	FROM @vehicleAnalysis AS C
	JOIN
	@stolenVehicleAnalysis AS V
	ON C.CameraID == V.CameraID;
	```
5.  In AnalyzeSpeedsByVehicle.usql, replace the existing OUTPUT statement to save these results, and sort the data in descending order of PercentStolen (you copy this code from **E:\\Labfiles\\Lab06\\Exercise3\\AnalyzeSpeedsByVehicle5.usql**):

	```
	OUTPUT @speedCameraAnalysis
	TO "/StolenVehicleSpeedAnalysis.csv"
	ORDER BY PercentStolen DESC
	USING Outputters.Csv(quoting : false, outputHeader : true);
	```
6.  In the **AnalyzeSpeedsByVehicle.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
7.  When the job has completed, close the **Job View** pane.
8.  Switch to the Azure portal.
9.  In Data Explorer, click **StolenVehicleSpeedAnalysis.csv**, and note that the data is now sorted in descending order of **PercentStolen**.
10.  On the **File Preview** blade, click **Download**.
11.  On the **Download** blade, click **Start Download now**.
12.  In the Internet Explorer message box, click the **Save** drop-down arrow, and then click **Save as**.
13.  In the **Save As** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise3**, and then click **Save**.
14.  In the **Confirm Save As** dialog box, click **Yes**.
15. In the Internet Explorer message box, click **Open folder**.
16. In File Explorer, double-click **StolenVehicleSpeedAnalysis.csv**.
17. In Microsoft Excel, view the data, and note that there are now 500 records (one record for each camera, plus the header). The data should indicate that between 2.45 percent and 3.76 percent of all cars passing speed cameras are stolen.
18. Close Microsoft Excel.
19. Switch to the Azure portal, close the **Download** and **File Preview** blades.

>**Result**: At the end of this exercise, you will have uploaded speed camera data to ADLS, examined the code in the custom reducer, deployed and tested the custom reducer, and then used the reducer to attempt to identify stolen vehicles in the speed camera data.

## Exercise 4: Use existing analytics, developed in R, in an ADLA solution

#### Task 1: Determining correlations by using R
1.  In the Azure portal, click **All resources**, click **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Sample Scripts**.
2.  On the **Sample Scripts** blade, click **More**, click **Install U-SQL Extensions**, and then click **OK**.
3.  Close the **Sample Scripts** blade.
4.  On the Start menu, type **Notepad**, and then press Enter.
5.  In Notepad, on the **File** menu, click **Open**.
6.  In the **Open** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise4**, click **All Files (\*.\*)**, click **SpeedAnalytics.R**, and then click **Open**.
7.  This is an R script that uses the ScaleR package to tidy up the input data, calculate the correlation between a vehicle speeding and being stolen, and return a data frame containing the data from the correlation matrix; remember that the reducer will call this code once for each camera (the reducer will group the data by camera ID).
8.  Close Notepad.
9.  Switch to the Azure portal.
10. Click **All resources**, click **adls&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Data Explorer**.
11. In Data Explorer, in the default (root) folder, click **Upload**.
12. On the **Upload files** blade, click the **file** button.
13. In the **Choose File to Upload** dialog box, go to **E:\\Labfiles\\Lab06\\Exercise4**, click **SpeedAnalytics.R**, and then click **Open**.
14. On the **Upload files** blade, click **Add selected files**.
15. After the file has uploaded, close the **Upload files** blade.
16. Switch to the instance of Visual Studio 2017 that has the **SpeedCameraAnalytics2** solution open.
17. In Solution Explorer, right-click **SpeedCameraAnalytics2**, point to **Add**, and then click **New Item**.
18. In the **Add New Item** dialog box, click **U-SQL Script**, in the **Name** box, type **AnalyzeUsingR.usql**, and then click **Add**.
19. In AnalyzeUsingR.usql, add the following statements to add references to the ExtR and CustomReducers assemblies (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR1.usql**):

	```
	REFERENCE ASSEMBLY [ExtR];
	REFERENCE ASSEMBLY CustomReducers;
	```
20.  In AnalyzeUsingR.usql, add the following statements to retrieve the stolen vehicle history data, and use the ReduceByRecoveredVehicles to return only vehicles that are currently marked as stolen (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR2.usql**):

	```
	@stolenVehicleHistory =
	EXTRACT VehicleRegistration string,
	DateStolen string,
	DateRecovered string // Can be empty
	FROM "/Stolen/{*}/{*}/{*}/VehicleData.csv"
	USING Extractors.Csv(skipFirstNRows: 1);

    @stolenVehicles =
	REDUCE @stolenVehicleHistory
	ON VehicleRegistration
	PRODUCE VehicleRegistration string,
	DateStolen DateTime
	USING new CustomReducers.ReduceByRecoveredVehicles();
	```
21.  In AnalyzeUsingR.usql, add the following statement to fetch the speed camera data from the catalog (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR3.usql**):

	```
	@speedData =
	SELECT CameraID,
	VehicleRegistration,
	Speed,
	SpeedLimit
	FROM VehicleData.dbo.SpeedCameraData;
	```
22.  In AnalyzeUsingR.usql, add the following statements to combine the rowsets over the vehicle registration column, and to perform a LEFT join because you want to include all rows from the speed camera data regardless of whether or not the vehicle snapped was speeding (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR4.usql**):

	```
	@sourceData =
	SELECT C.CameraID AS CameraID,
	C.VehicleRegistration AS VehicleRegistration,
	C.Speed AS Speed,
	C.SpeedLimit AS SpeedLimit,
	V.DateStolen.ToString() AS DateStolen
	FROM @speedData AS C
	LEFT JOIN
	@stolenVehicles AS V
	ON C.VehicleRegistration == V.VehicleRegistration;
	Note that this statement will cause the DateStolen column to have a null value in the resulting rowset for all cars that are not stolen.
	```
23.  In AnalyzeUsingR.usql, add the following statement to deploy the script containing the R code to be run (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR5.usql**):

	```
	DEPLOY RESOURCE @"/SpeedAnalytics.R";
	```
24.  In AnalyzeUsingR.usql, add the following statement to call the R script to generate a correlation matrix for each camera, showing whether there is any correlation between cars speeding and being stolen (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR6.usql**):

	```
	@RScriptOutput =
	REDUCE @sourceData
	ON CameraID
	PRODUCE CameraID string, Correlation double
	USING new Extension.R.Reducer(scriptFile:"SpeedAnalytics.R", rReturnType:"dataframe", stringsAsFactors:false);
	```
25.  In AnalyzeUsingR.usql, add the following statement to save the results (you copy this code from **E:\\Labfiles\\Lab06\\Exercise4\\AnalyzeUsingR7.usql**):

	```
	OUTPUT @RScriptOutput
	TO "/CorrelationMatrixData.csv"
	ORDER BY CameraID
	USING Outputters.Csv(quoting : false, outputHeader : true);
	```
26.  In the **AnalyzeUsingR.usql** pane, in the toolbar, set the **ADLA instance** to **speedsdla&lt;_your name_&gt;&lt;_date_&gt;**, and then click **Submit**.
27.  When the job has completed, close the **Job View** pane.
28.  Switch to the Azure portal.
29.  In Data Explorer, click **CorrelationMatrixData.csv**, and note that there appears to be little correlation between cars being stolen and being caught speeding; this is not surprising for this dataset because all of the data is generated randomly. However, there might be more of a correlation in the real world.
30.  Close the **File Preview** blade.

>**Result**: At the end of this exercise, you will have used an R script script in a U-SQL job.

**Question**: Why do you need to deploy your own custom extractor for JSON file data?

**Question**: Why is it important to optimize the table structure in your ADLA catalog?

©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
