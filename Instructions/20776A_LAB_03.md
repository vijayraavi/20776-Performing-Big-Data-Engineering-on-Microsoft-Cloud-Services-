# Module 3: Performing Custom Processing in Azure Stream Analytics

# Lab: Performing custom processing with Stream Analytics

### Scenario
You work for Adatum as a data engineer, and you’ve been asked to build a traffic surveillance system for traffic police. This system must be able to analyze significant amounts of dynamically streamed data—captured from speed cameras and automatic number plate recognition (ANPR) devices—and then crosscheck the outputs against large volumes of reference data that holds vehicle, driver, and location information. Fixed roadside cameras, hand-held cameras (held by traffic police), and mobile cameras (in police patrol cars) are used to monitor traffic speeds and raise an alert if a vehicle is travelling too quickly for the local speed limit. The cameras also have built-in ANPR software that reads vehicle registration plates.

For the second phase of the project, you will use Stream Analytics, together with Event Hub, IoT Hubs, Service Bus, Machine Learning, and custom applications to:
- Post messages to a Service Bus queue for all vehicles that are speeding, by using a simple JavaScript UDF function to determine whether a vehicle’s speed is above a particular limit.
- Identify vehicles that appear to be using the same registration number, by using a JavaScript UDF function to determine whether a vehicle with the same registration (not necessarily speeding) has been spotted at two locations that are an impossible distance apart within a given timeframe.
- Identify traffic flow issues, such as road blockages, or excessive speeds, by using Machine Learning with Stream Analytics to detect consistent speed anomalies from a speed camera; for example, if speeds are consistently very low for a period, the cause could be a traffic accident or incident.

### Objectives
After completing this lab, you will be able to:
- Use a Stream Analytics UDF function to identify specific data points.
- Use a Stream Analytics UDF function to identify duplicate data records.
- Use Machine Learning with Stream Analytics to identify data anomalies.

### Lab Setup
Estimated time: 90 minutes

Virtual machine: **20776A-LON-DEV**

User name: **ADATUM\\AdatumAdmin**

Password: **Pa55w.rd**

This lab uses the following resources from Lab 2, all in resource group **CamerasRG**:
- **Data Lake Store**: adls&lt;_your name_&gt;&lt;_date_&gt;
- **Event Hub**: camerafeeds&lt;_your name_&gt;&lt;_date_&gt;
- **IoT Hub**: patrolcars&lt;_your name_&gt;&lt;_date_&gt;
- **Service Bus**: locationalerts&lt;_your name_&gt;&lt;_date_&gt;
- **Storage account**: datastore&lt;_your name_&gt;&lt;_date_&gt;
- **Streaming Analytics jobs**: TrafficAnalytics, PatrolCarAnalytics

## Exercise 1: Use a Stream Analytics UDF function to identify specific data points

### Scenario
For the first part of this next phase of the traffic surveillance system, you will add functionality to identify speeding vehicles. In this exercise, you will add logic to the analytics that capture vehicle speeds, and post a message to a Service Bus queue for all vehicles that are speeding. You will add a simple JavaScript function that ascertains whether a vehicle is speeding. You will then use an updated version of the app from Lab 2 to display the velocity of cars that were caught speeding.

The main tasks for this exercise are as follows:
1. Update the event hub and add a consumer group
2. Add a queue to the Service Bus
3. Configure the Location Alerts app
4. Reconfigure the TrafficAnalytics Stream Analytics job
5. Start the Stream Analytics jobs
6. Start the Speed Camera app
7. Start the Patrol Car app
8. Start the Location Alerts app
9. View the results
10. Close jobs and apps

#### Task 1: Update the event hub and add a consumer group
- In the event hub, create a new consumer group called **cameradatafeed3**.

#### Task 2: Add a queue to the Service Bus
- In the Service Bus, create a new queue called **SpeedCameraAlerts**.

#### Task 3: Configure the Location Alerts app
1.  Start Visual Studio, and open the **E:\\Labfiles\\Lab03\\LocationAlerts\\LocationAlerts** project.
2.  Edit **ConfigSettings.txt**, and replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
3.  Edit ConfigSettings.txt, and replace **YourPrimaryKey** with the primary key from the Service Bus connection string you copied to **Config\_details.txt** in Module 2.
4.  Build the solution, and verify that the app compiles successfully; do not start the app.

#### Task 4: Reconfigure the TrafficAnalytics Stream Analytics job
1.  Add an input to the TrafficAnalytics Stream Analytics job, with the following details:
    - **Input alias**: CameraDataFeed3
    - **Source Type**: Data stream
    - **Source**: Event hub
    - **Import option**: Use event hub from current subscription
    - **Event hub consumer group**: cameradatafeed3
    - Leave all other settings at their defaults
2.  Add an output to the TrafficAnalytics Stream Analytics job, with the following details:
    - **Output alias**: SpeedCameraAlerts
    - **Sink**: Service bus Queue
    - **Import option**: Use queue from current subscription
    - **Queue name**: SpeedCameraAlerts
    - Leave all other settings at their defaults
3.  Add a function to the TrafficAnalytics Stream Analytics job, with the following details:
    - **Function Alias**: IsSpeeding
4.  Replace the template function code text with the following:

    ```
    // UDF that returns an integer value indicating whether a vehicle is speeding
    function main(speedLimit, speed) {
    return (speed > speedLimit) ? 1 : 0;
    }
    ```
You copy the preceding code from **E:\\Labfiles\\Lab03\\UDF1.txt**.

5.  Add the following to the end of the existing query, to send information about speeding cars to the speed camera message queue:

    ```
    SELECT
    CameraID,LocationLatitude,LocationLongitude,SpeedLimit,VehicleRegistration,Speed
    INTO
    SpeedCameraAlerts
    FROM
    CameraDataFeed3
    WHERE
    UDF.IsSpeeding(SpeedLimit, Speed) = 1
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab03\\ASAquery1.txt**.

6.  Set the number of streaming units to **12**, if this is not already set.

#### Task 5: Start the Stream Analytics jobs
1.  Start the **TrafficAnalytics** and **PatrolCarAnalytics** Stream Analytics jobs.
2.  Wait until the jobs have been successfully started before continuing with the lab.

#### Task 6: Start the Speed Camera app
1.  Start a new instance of Visual Studio, and open the **E:\\Labfiles\\Lab03\\SpeedCameraDevice\\SpeedCameraDevice** project.
2.  In App.config, in the **appSettings** section, in the **ServiceBusConnectionString** key, replace **YourNamespace** with **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**, and replace **YourPrimaryKey** with the event hub primary key you copied to **Config\_details.txt**.
3.  Set **SpeedCameraDriver** as the **Startup Project**.
4.  Build the solution, verify that the app compiles successfully, and then start the app.
5.  Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.

#### Task 7: Start the Patrol Car app
1.  Start a new instance of Visual Studio, and open the **E:\\Labfiles\\Lab03\\PatrolCarDevice\\PatrolCarDevice** project.
2.  In App.config, in the **appSettings** section, in the **ServiceBusConnectionString** key, replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**, and replace **YourServiceBusPrimaryKey** with the Service Bus primary key you copied to **Config\_details.txt**.
3.  In App.config, in the **appSettings** section, in the **IoTHubConnectionString** and **IotHubUri** keys, replace **YourIoTHub** with **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
4.  In App.config, in the **appSettings** section, in the **IoTHubConnectionString** key, replace the SharedAccessKey value **YourIoTHubPrimaryKey** with the SharedAccessKey from the IoT Hub connection string you copied to **Config\_details.txt**.
5.  Build the solution, verify that the app compiles successfully, and then start the app.
6.  Verify that the app opens a console window displaying the generated positions of patrol cars that are being sent to the IoT Hub.

#### Task 8: Start the Location Alerts app
1.  Start the **LocationAlerts** project on the local machine.
2.  Verify that the app displays a map (of London), and starts to show the positions of speeding vehicles (and their speed), and the positions of dispatched patrol cars.
>**Note**: The map may take 5-10 minutes to display, and you might also need to wait before all the data appears on the map.

#### Task 9: View the results
1.  Let the system run for a few minutes, to give it time to detect some speeding vehicles, and then observe the fun!
2.  Note that the PatrolCarDevice project reports messages when a patrol car is dispatched to chase a speeding vehicle. You should also see the location of the patrol car change to move to the location reported for the speeding vehicle in the LocationAlerts app.

#### Task 10: Close jobs and apps
1.  Close the PatrolCarAnalytics and TrafficAnalytics jobs.
2.  Reset the **TrafficAnalytics** job to use **1** streaming unit.
3.  Stop the LocationAlerts, PatrolCar, and SpeedCameraDevice apps.
4.  Close all the instances of Visual Studio.

>**Result**: At the end of this exercise, you will have added a new consumer group to your event hub, added a new queue to your Service Bus, reconfigured an existing Stream Analytics job to use these resources, and added a UDF that returns an integer value indicating whether a vehicle is speeding. You will also have tested this logic using Visual Studio apps.

## Exercise 2: Use a Stream Analytics UDF to identify duplicate data records

### Scenario
For the next part of the traffic surveillance system, you will build logic to identify vehicles that appear to be using the same registration number. In this exercise, you will use a JavaScript function to determine whether a vehicle with the same registration (not necessarily speeding) has been spotted at two locations that are an impossible distance apart within a given timeframe. You will store the details (times, registrations, locations), and this data will be used in a later lab exercise.

The main tasks for this exercise are as follows:
1. Update the event hub and add a consumer group
2. Create and configure a new Stream Analytics job
3. Start the Speed Camera app
4. Examine the generated data
5. Close jobs and apps

#### Task 1: Update the event hub and add a consumer group
- In the event hub, create a new consumer group called **vehiclefeed**.

#### Task 2: Create and configure a new Stream Analytics job
1.  Create a new Stream Analytics job called **RegistrationAnalytics**, with the following details:
    - **Resource group (Use existing)**: CamerasRG
    - **Location**: Use the same as you used for the Data Lake Store
2.  Wait until the Stream Analytics job has deployed before continuing with the lab.
3.  Add an output to the RegistrationAnalytics Stream Analytics job, with the following details:
    - **Output alias**: DuplicateVehicles
    - **Sink**: Data Lake Store
    - Click **Authorize**
    - **Path prefix pattern**: Duplicates/{date}/{time}
    - Leave all other settings at their default
4.  Wait until the output has been successfully created before continuing with the lab.
5.  Add an input to the RegistrationAnalytics Stream Analytics job, with the following details:
    - **Input alias**: VehicleFeed
    - **Source Type**: Data stream
    - **Source**: Event hub
    - **Import option**: Use event hub from current subscription
    - **Event hub consumer group**: vehiclefeed
    - Leave all other settings at their defaults
6.  Wait until the input has been successfully created before continuing with the lab.
7.  Add a function to the RegistrationAnalytics Stream Analytics job, with the following details:
    - **Function Alias**: DuplicatedVehicle
8.  Replace the template function code text with the code from **E:\\Labfiles\\Lab03\\UDF2.txt**.
9.  Add the following query to the RegistrationAnalytics Stream Analytics job to send information about suspicious vehicles to the Data Lake Store:

    ```
    SELECT
    UDF.DuplicatedVehicle(Collect())
    INTO
    DuplicateVehicles
    FROM
    VehicleFeed
    GROUP BY
    TumblingWindow(minute, 2)
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab03\\ASAquery2.txt**.

10.  Start the RegistrationAnalytics Stream Analytics job.
11.  Wait until the job has been successfully started before continuing with the lab.

#### Task 3: Start the Speed Camera app
1.  Start Visual Studio, and open the **E:\\Labfiles\\Lab03\\SpeedCameraDevice2\\SpeedCameraDevice** project.
2.  In **App.config**, in the **appSettings** section, in the **ServiceBusConnectionString** key, replace **YourNamespace** with **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**, and replace **YourPrimaryKey** with the event hub primary key you copied to **Config\_details.txt**.
3.  Set **SpeedCameraDriver** as the **Startup Project**.
4.  Build the solution, verify that the app compiles successfully, and then start the app.
5.  Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.

#### Task 4: Examine the generated data
1.  Use the Data Explorer in the Azure portal to view the contents of the JSON file in the Data Lake Duplicates folder.
2.  Verify that the data includes duplicate registration numbers, and the locations at which they have been detected.

#### Task 5: Close jobs and apps
1.  Close the **RegistrationAnalytics** job.
2.  Stop the **SpeedCameraDevice** app.
3.  Close Visual Studio.

>**Result**: At the end of this exercise, you will have added a new consumer group to your event hub, and created a new Stream Analytics job that uses a UDF to identify duplicate vehicle registrations. You will also have tested this logic using a Visual Studio app.

## Exercise 3: Use Machine Learning with Stream Analytics to identify data anomalies

### Scenario
For the final part of this phase of the traffic surveillance system, you will use Machine Learning with Stream Analytics to detect consistent speed anomalies from a speed camera, to help locate traffic accidents or other road incidents.
In this exercise, you will use Machine Learning with Stream Analytics to detect consistent speed anomalies from a speed camera. If speeds are consistently very low for a period, the cause could be a traffic accident or incident, so you should display a message on screen using an updated version of the app from Exercise 1.

The main tasks for this exercise are as follows:
1. Update the event hub and add a consumer group
2. Create and configure a new Stream Analytics job
3. Configure and start the Speed Camera app
4. Stop the Speed Camera app and the CaptureTrafficData Stream Analytics job
5. Download the training data
6. Create a Machine Learning workspace
7. Create a machine learning experiment
8. Create a trained model
9. Expose the trained model as a web service
10. Add another consumer group to the Speed Camera event hub
11. Create a new Service Bus queue
12. Create and configure a new Stream Analytics job
13. Start the Stream Analytics jobs
14. Configure the Location Alerts app
15. Start the Patrol Car and Speed Camera apps
16. Start the Location Alerts app and view the results
17. Lab closedown

#### Task 1: Update the event hub and add a consumer group
- In the event hub, create a new consumer group called **cameradatafeed4**.

#### Task 2: Create and configure a new Stream Analytics job
1.  Create a new Stream Analytics job called **CaptureTrafficData**, with the following details:
    - **Resource group (Use existing)**: CamerasRG
    - **Location**: Use the same location as you used for the Data Lake Store
2.  Wait until the Stream Analytics job has deployed before continuing with the lab.
3.  Add an input to the CaptureTrafficData Stream Analytics job, with the following details:
    - **Input alias**: CameraDataFeed4
    - **Source Type**: Data stream
    - **Source**: Event hub
    - **Import option**: Use event hub from current subscription
    - **Event hub consumer group**: cameradatafeed4
    - Leave all other settings at their defaults
4.  Add an output to the CaptureTrafficData Stream Analytics job, with the following details:
    - **Output alias**: TrafficData
    - **Sink**: Data Lake Store
    - Click **Authorize**
    - **Path prefix pattern**: TrafficTrainingData/
    - **Event serialization format**: CSV
    - Leave all other settings at their defaults
5.  Add the following query to the CaptureTrafficData Stream Analytics job:

    ```
    SELECT
    CameraID,Speed,DATEPART(hour, Time)
    AS
    HourOfDay
    INTO
    TrafficData
    FROM
    CameraDataFeed4
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab03\\ASAquery3.txt**.

6.  Start the CaptureTrafficData Stream Analytics job.
7.  Wait until the job has been successfully started before continuing with the lab.

#### Task 3: Configure and start the Speed Camera app
1.  Start Visual Studio, and open the **E:\\Labfiles\\Lab03\\SpeedCameraDevice3\\SpeedCameraDevice.sln** project.
2.  In **App.config**, in the **appSettings** section, in the **ServiceBusConnectionString** key, replace **YourNamespace** with **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**, and replace **YourPrimaryKey** with the event hub primary key you copied to **Config\_details.txt in Lab 2, Ex 3**.
3.  Set **SpeedCameraDriver** as the **Startup Project**.
4.  Build the solution, verify that the app compiles successfully, and then start the app.
5.  Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.
6.  Let the app run for at least five minutes.

#### Task 4: Stop the Speed Camera app and the CaptureTrafficData Stream Analytics job
1.  Stop the Speed Camera app and the CaptureTrafficData Stream Analytics job.
2.  Use the Data Explorer in the Azure portal to view the CSV file in the **TrafficTrainingData** folder.
3.  Verify that the data includes the speed camera name, recorded traffic speed, and time from your Stream Analytics query.
Note that this file contains the locations of the cameras used by the training run. For consistency, when you run the app in "non-training" mode, it will read these same locations for the speed cameras. If you run the app in training mode again, make sure that you delete this file first, otherwise you will get duplicate speed cameras—but at different locations.

#### Task 5: Download the training data
1.  Download the CSV file, and save it as **E:\\Labfiles\\Lab03\\TrafficData.csv**.
2.  Open this file in Excel, and verify that the downloaded file contains data on speed camera name, recorded traffic speed, and time.

#### Task 6: Create a Machine Learning workspace
1.  Create a new Machine Learning workspace called Traffic, with the following details:
    - **Resource group (Use existing)**: CamerasRG
    - **Location**: select the nearest location to the one you used for the Data Lake Store
    - **Storage account (Create new)**: traffic&lt;_your name_&gt;&lt;_date_&gt;
    - **Workspace pricing tier**: Standard
    - **Web service plan (Create new)**: accept the default name
2.  Click **Web service plan pricing tier**, click **DevTest Standard**, and then click **Select**.
3.  Wait until the workspace has been deployed before continuing.

#### Task 7: Create a machine learning experiment
1.  Launch Machine Learning Studio, and, if prompted, sign in using your Azure account credentials.
2.  Upload **E:\\Labfiles\\Lab03\\TrafficData.csv** as a new dataset, of the type **Generic CSV File with a header**.
3.  Create a new blank experiment, and drag **TrafficData.csv** to the workspace canvas.
4.  Drag a **Split Data** module to the experiment canvas, below the dataset.
5.  Connect the output of **TrafficData.csv** to the upper input port of the **Split Data** module.
6.  In the **Split Data** properties, set the **Fraction of rows** to **0.7**.
7.  Drag a **Train Anomaly Detection Model** module to the experiment canvas, below the **Split Data** module.
8.  Connect the leftmost output of the **Split Data** module to the upper right input port of the **Train Anomaly Detection Model** module (this is the Dataset input).
9.  Drag a **One-Class Support Vector Machine Model** module to the experiment canvas, to the left of the **Split Data** module.
10. Connect the output of the **One-Class Support Vector Machine Model** module to the upper left input port of the **Train Anomaly Detection Model** module (this is the untrained model input).
11. Drag a **Score Model** module to the experiment canvas, below the **Train Anomaly Detection Model** module.
12. Connect the output of the **Train Anomaly Detection Model** module to the leftmost input of the **Score Model** module (this is the trained model input), and the rightmost output of the **Split Data** module to the rightmost input of the **Score Model** module (this is the Dataset input).
13. Save the experiment, and then run it.
14. When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.

#### Task 8: Create a trained model
1.  Save the Train Anomaly Detection Model module, as a trained model called **Trained TrafficSpeeds**.
2.  Delete the **One-Class Support Vector Machine** and **Train Anomaly Detection Model** modules.
3.  Drag **Trained TrafficSpeeds** to the experiment canvas, to the left of the **Split Data** module.
4.  Connect the output of the **Trained TrafficSpeeds** module to the leftmost input of the **Score Model** module.

#### Task 9: Expose the trained model as a web service
1.  Create the web service for the model.
2.  Delete the connection from the **Web service input** module to the **Split Data** module.
3.  Connect the output of the **Web service input** module to the rightmost input of the **Score Model** module.
4.  Save the experiment, and then run it (to validate the changes).
5.  When the experiment has finished running, all modules will show a green check mark to indicate that they have successfully finished.
6.  Deploy the web service, in Classic mode.
7.  Copy the **API key** to the **Config\_details.txt** file, and label it **Web service API key**.
8.  Go to the **New Web Services Experience** for the experiment, and configure the endpoint with the description: **Traffic speed anomaly detection web service**.
9.  From the **Use endpoint** page, copy the **Request-Response** URL, and save it to **Config\_details.txt** file.

#### Task 10: Add another consumer group to the Speed Camera event hub
- In the event hub, create a new consumer group called **cameraspeedanomalyfeed**.

#### Task 11: Create a new Service Bus queue
1.  Create a new Service Bus queue called **TrafficJamAlerts**.
2.  Wait until the queue has been successfully created before continuing with the lab.

#### Task 12: Create and configure a new Stream Analytics job
1.  Create a new Stream Analytics job called **DetectSpeedAnomalies**, with the following details:
    - **Resource group (Use existing)**: CamerasRG
    - **Location**: Use the same as you used for the Data Lake Store
2.  Wait until the Stream Analytics job has deployed before continuing with the lab.
3.  Configure the Stream Analytics job to use **12** streaming units.
4.  Add an input to the **DetectSpeedAnomalies** Stream Analytics job, with the following details:
    - **Input alias**: SpeedCameraData
    - **Source Type**: Data stream
    - **Source**: Event hub
    - **Import option**: Use event hub from current subscription
    - **Event hub consumer group**: cameraspeedanomalyfeed
    - Leave all other settings at their defaults
5.  Add an output to the **DetectSpeedAnomalies** Stream Analytics job, with the following details:
    - **Output alias**: TrafficData
    - **Sink**: Data Lake Store
    - Click **Authorize**
    - **Path prefix pattern**: TrafficJams/{date}/{time}
    - **Event serialization format**: JSON
    - Leave all other settings at their defaults
6.  Add a function to the **DetectSpeedAnomalies** Stream Analytics job, with the following details:
    - **Function Alias**: SpeedAnomaly
    - **Function Type**: AzureML
    - **Import option**: Import from a different subscription
    - **URL**: paste the Request-Response URL that you copied to Config\_details.txt
    - **Key**: paste the web service API key that you copied to Config\_details.txt
7.  After creating the function, you should ignore the Adding function notification as this never goes away!
8.  Add another output to the **DetectSpeedAnomalies** Stream Analytics job, with the following details:
    - **Output alias**: TrafficJamAlerts
    - **Sink**: Service Bus queue
    - **Import option**: Use queue from current subscription
    - **Queue name**: trafficjamalerts
    - Leave all other settings at their defaults
9.  Add the following query to the **DetectSpeedAnomalies** Stream Analytics job:

    ```
    WITH
    SpeedAnomalies
    AS
    (SELECT CameraID, AVG(Speed) AS AvgSpeed, SpeedAnomaly(CameraID, AVG(Speed), DATEPART(hour, MAX(Time))) AS Results, DATEPART(hour, MAX(Time)) AS HourOfDay
    FROM
    SpeedCameraData
    TIMESTAMP BY
    Time
    GROUP BY
    CameraID, TumblingWindow(minute, 2))

    SELECT
    CameraID, AvgSpeed, HourOfDay
    INTO
    TrafficData
    FROM
    SpeedAnomalies
    WHERE
    Results.[Scored Labels] = '1'

    SELECT
    CameraID, AvgSpeed
    INTO
    TrafficJamAlerts
    FROM
    SpeedAnomalies
    WHERE
    Results.[Scored Labels] = '1'
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab03\\ASAquery4.txt**.

#### Task 13: Start the Stream Analytics jobs
1.  Start the **DetectSpeedAnomalies**, **TrafficAnalytics** and **PatrolCarAnalytics** Stream Analytics jobs.
2.  Wait until the jobs have been successfully started before continuing with the lab.

#### Task 14: Configure the Location Alerts app
1.  Start a new instance of Visual Studio, and open the **E:\\Labfiles\\Lab03\\LocationAlerts2\\LocationAlerts** project.
2.  Edit **ConfigSettings.txt**, and replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
3.  Edit **ConfigSettings.txt**, and replace **YourPrimaryKey** with the primary key from the Service Bus connection string you copied to **Config\_details.txt** in Exercise 2.
4.  Build the solution, and verify that the app compiles successfully; do not start the app.

#### Task 15: Start the Patrol Car and Speed Camera apps
1.  Start a new instance of Visual Studio, and open the **E:\\Labfiles\\Lab03\\PatrolCarDevice\\PatrolCarDevice** project.
2.  Start the app, and verify that the app opens a console window displaying the generated positions of patrol cars that are being sent to the IoT Hub.
3.  In the **SpeedCameraDevice** instance of Visual Studio, in **App.config**, in the **appSettings** section, in the **TrainingRun** key, replace **true** with **false**.
4.  Build the solution, verify that the app compiles successfully, and then start the app.
5.  Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.

#### Task 16: Start the Location Alerts app and view the results
1.  In the **LocationAlerts** instance of Visual Studio, start the app to run on the local machine.
2.  Verify that the app displays a map (of London), and starts to show the positions of speeding anomalies, the positions of dispatched patrol cars, and traffic blockage alert messages where traffic is not moving (speeds = 0 mph).
> **Note**: The map may take 5-10 minutes to display, and you might also need to wait before all the data appears on the map.

#### Task 17: Lab closedown
1.  Stop the **TrafficAnalytics**, **DetectSpeedAnomalies**, and **PatrolCarAnalytics** jobs.
2.  Reset the **TrafficAnalytics** and **DetectSpeedAnomalies** jobs to use **1** streaming unit.
3.  Close the **LocationAlerts**, **PatrolCarDevice**, and **SpeedCameraDevice** apps.
4.  Do not remove the Azure resources (resource group, Stream Analytics jobs, event hub, IoT hub, and storage); these resources will be used in later labs.
5.  Close Internet Explorer.

>**Result**: At the end of this exercise, you will have added new consumer groups to your event hub, and created a new Stream Analytics job that works with a Visual Studio app to generate training data. You will then create a machine learning experiment to detect anomalous data, train your model using the generated training data, and then deploy the trained model as a web service. You will also have created a second new Stream Analytics job that uses the Machine Learning web service, and the model using Visual Studio apps.

**Question**: How might you use Stream Analytics UDF functions to identify specific data points within your organization?

**Question**: What requirements does your organization have for deduplicating information?

©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
