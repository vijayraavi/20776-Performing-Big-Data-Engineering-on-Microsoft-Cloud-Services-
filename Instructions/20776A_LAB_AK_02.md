# Lab Answer Key: Module 2: Processing Event Streams using Azure Stream Analytics
# Lab: Process event streams with Stream Analytics

## Exercise 1: Create a Stream Analytics job to process event hub data

#### Task 1: Create a Data Lake Store
1.	Ensure that the **MT17B-WS2016-NAT**, **20776A-LON-DC**, and **20776A-LON-DEV** virtual machines are running, and then log on to **20776A-LON-DEV** as **ADATUM\AdatumAdmin** with the password **Pa55w.rd**.
2.	On the Start menu, type **Internet Explorer**, and then press Enter.
3.	In Internet Explorer, go to http://portal.azure.com, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
4.  In the Azure portal, click **+ New**, click **Storage**, and then click **Data Lake Store**.
5.  On the **Data Lake Store** blade, click **Create**.
6.  On the **New Data Lake Store** blade, in the **Name** box, type **adls&lt;_your name_&gt;&lt;_date_&gt;**.
7.  Under **Resource** **Group**, click **Create new**, and type **CamerasRG**.
8.  In the **Location** list, select your nearest location from the currently available Data Lake Store regions.
9.  Leave all other settings at their defaults, and click **Create**.
10.	Wait until the storage has deployed before continuing with the lab.

#### Task 2: Create an event hubs namespace and hub
1.  In the Azure portal, click **+ New**, click **Internet of Things**, and then click **Event Hubs**.
2.  On the **Create namespace** blade, in the **Name** box, type **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
3.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
4.  In the **Location** list, select the same location as you used for the Data Lake Store.
5.  Leave all other settings at their defaults, and click **Create**.
6.  Wait until the namespace has deployed before continuing with the lab.
7.  Click **All resources**, click **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**, and then click **+ Event Hub**.
8.  On the **Create Event Hub** blade, in the **Name** box, type **traffic**.
9.  Set the **Partition Count** to **16**.
10. Leave all other settings at their defaults, and click **Create**.
11. Wait until the event hub has deployed before continuing with the lab.
12. On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;** blade, under **ENTITIES**, click **Event Hubs**, and then click **traffic**.
13. On the **traffic** blade, click **+ Consumer Group**.
14. On the **Create consumer group** blade, in the **Name** box, type **cameradatafeed**, and then click **Create**.
15. On the **traffic** blade, click **+ Consumer Group**.
16. On the **Create consumer group** blade, in the **Name** box, type **cameradatafeed2**, and then click **Create**.
17. Close the traffic blade.
18. On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt; - Event Hubs** blade, under **SETTINGS**, click **Shared access policies**, and then click **RootManageSharedAccessKey**.
19. Next to the **PRIMARY KEY**, click the **Click to copy** button, to copy the primary key to the clipboard.
20. On the Start menu, type **Notepad**, and then press Enter.
21. In Notepad, type **Event hub primary key**, and press Enter.
22. On the **Edit** menu, click **Paste**, to store the primary key.
23. On the **File** menu, click **Save**.
24. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab02**, in the **File name** box, type **Config\_details.txt**, and then click **Save**.

#### Task 3: Create a Stream Analytics job
1.  Switch to the Azure portal, click **+ New**, click **Data + Analytics**, and then click **Stream Analytics** **job**.
2.  On the **New Stream Analytics** **Job** blade, in the **Job name** box, type **TrafficAnalytics**.
3.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
4.  In the **Location** list, select the same location as you used for the Data Lake Store, and then click **Create**.
5.  Wait until the Stream Analytics job has deployed before continuing with the lab.

#### Task 4: Configure Stream Analytics job inputs
1.  In the Azure portal, click **All resources**, and then click **TrafficAnalytics**.
2.  On the **TrafficAnalytics** blade, under **JOB TOPOLOGY**, click **Inputs**, and then click **+ Add**.
3.  On the **New input** blade, enter the following details:
 -   **Input alias**: CameraDataFeed
 -   **Source Type**: Data stream
 -   **Source**: Event hub
 -   **Import option**: Provide event hub settings manually
 -   **Service bus namespace**: camerafeeds&lt;_your name_&gt;&lt;_date_&gt; as you created earlier
 -   **Event hub name**: traffic
 -   **Event hub policy name**: RootManageSharedAccessKey
 -   **Event hub policy key**: Paste the key you copied into Config\_details.txt
 -   **Event hub consumer group**: cameradatafeed
4. Leave all other settings at their defaults, and click **Create**.
5. Wait until the input has been successfully created before continuing with the lab.
6. On the **TrafficAnalytics - Inputs** blade, click **+ Add**.
7.  On the **New input** blade, enter the following details:
 -   **Input alias**: CameraDataFeed2
 -   **Source Type**: Data stream
 -   **Source**: Event hub
 -   **Import option**: Provide event hub settings manually
 -   **Service bus namespace**: camerafeeds&lt;_your name_&gt;&lt;_date_&gt; as you created earlier
 -   **Event hub name**: traffic
 -   **Event hub policy name**: RootManageSharedAccessKey
 -   **Event hub policy key**: Paste the key you copied to Config\_details.txt
 -   **Event hub consumer group**: cameradatafeed2
8. Leave all other settings at their defaults, and click **Create**.
9. Wait until the input has been successfully created before continuing with the lab.

#### Task 5: Configure Stream Analytics job outputs
1.  On the **TrafficAnalytics - Inputs** blade, under **JOB TOPOLOGY**, click **Outputs**, and then click **+ Add**.
2.  On the **New output** blade, enter the following details, and then click **Create**:
 -   **Output alias**: VisualData
 -   **Sink**: Power BI
 -   Click **Authorize**, and sign in using your Power BI credentials
 -   **Dataset Name**: TrafficData
 -   **Table Name**: TrafficData
3. Wait until the output has been successfully created before continuing with the lab.
4. On the **TrafficAnalytics - Outputs** blade, click **+ Add**.
5. On the **New output** blade, enter the following details:
 - **Output alias**: StoredData
 -   **Sink**: Data Lake Store
 -   Click **Authorize**, and sign in using your Power BI credentials (you might not be prompted this time)
 -   **Path prefix pattern**: SpeedData/{date}/{time}
6. Leave all other settings at their defaults, and click **Create**.
7. Wait until the output has been successfully created before continuing with the lab.

#### Task 6: Configure a Stream Analytics job query
1.  On the **TrafficAnalytics - Outputs** blade, under **JOB TOPOLOGY**, click **Query**, and then replace the template query text with the following:

    ```
    SELECT
    CameraID,VehicleRegistration,Speed,SpeedLimit,LocationLatitude,LocationLongitude,Time
    INTO
    StoredData
    FROM
    CameraDataFeed

    SELECT
    CameraID, AVG(Speed) AS AvgSpeed
    INTO
    VisualData
    FROM
    CameraDataFeed2
    TIMESTAMP BY
    Time
    GROUP BY
    CameraID, TumblingWindow(second, 30)
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab02\\ASAquery1.txt**.

2. Click **Save**, and then click **Yes**.

#### Task 7: Start a Stream Analytics job
1.	On the **TrafficAnalytics - Query** blade, click **Overview**, and then click **Start**.
2.	On the **Start job** blade, click **Now**, and then click **Start**.
3.	Wait until the job has successfully started before continuing with the lab.

#### Task 8: Generate event hub data for processing with Stream Analytics
1.  On the Start menu, type **Visual Studio 2017**, and then press Enter.
2.  On the **File** menu, point to **Open**, and then click **Project/Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\SpeedCameraDevice** folder, click **SpeedCameraDevice.sln**, and then click **Open**.
4.  In Solution Explorer, double-click **App.config**.
5.  In App.config, in the **appSettings** section, replace the **Endpoint** value **YourNamespace** with **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
6.  In App.config, in the **appSettings** section, replace the **SharedAccessKey** value **YourPrimaryKey** with the primary key you copied to **Config\_details.txt**.
7.  In Solution Explorer, right-click **SpeedCameraDriver**, and then click **Set as StartUp Project**.
8.  On the **Build** menu, click **Build Solution**.
9.  Verify that the app compiles successfully, and then click **Start**.
10. Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.

#### Task 9: Visualize Stream Analytics output using Power BI
1.  In Internet Explorer, click **+** to create a new tab, and go to .
2.  In Power BI, if prompted, sign in using your Power BI account credentials.
3.  Click **My Workspace**, and then click **DataSets**.
4.  Verify that a streaming dataset named **TrafficData** is available (if this does not appear, wait a few minutes, and then refresh the page).
5.  Click **+ Create**, and then click **Dashboard**.
6.  In the **Create dashboard** dialog box, in the **Dashboard name** box, type **Traffic**, and then click **Create**.
7.  Click **+ Add tile**.
8.  In the **Add tile** pane, click **CUSTOM STREAMING DATA**, and then click **Next**.
9.  In the **Add a custom streaming data tile** pane, click **TrafficData**, and then click **Next**.
10. In the **Add a custom streaming data tile** pane, in the **Visualization Type** list, click **Clustered column chart**.
11. Under **Legend**, click **Add value**, and then select **cameraid**.
12. Under **Value**, click **Add value**, and then select **avgspeed**.
13. Under **Time window to display**, select **30 seconds**, and then click **Next**.
14. In the **Tile details** pane, in the **Title** box, type **Camera speeds**, and then click **Apply**.
15. Leave the tile to display for a few minutes; note that it summarizes information about the average speeds recorded by each camera during the last 30-second interval.

#### Task 10: View Stream Analytics output in Data Lake Store
1.  Switch to the Azure portal, click **All resources**, and then click **adls&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **Data Explorer**.
3.  On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **SpeedData**, and then click all the subfolders.
4.  Click the log file to view the contents in File Preview; verify that the data includes the fields you specified in your Azure Stream Analytics query.
5.  Close the **File Preview** blade.
6.  Click **All resources**, and then click **TrafficAnalytics**.
7.  On the **TrafficAnalytics** blade, click **Stop**, and then click **Yes**.
8.  Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.

>**Result**: At the end of this exercise, you will have created an Azure Data Lake Store, an event hubs namespace, and a Stream Analytics job. You will then use Stream Analytics to process event hubs data, and view the results in a Power BI dashboard and in Data Lake Store.

## Exercise 2: Create a Stream Analytics job to process IoT hub data

#### Task 1: Create an IoT hub
1.  In the Azure portal, click **+ New**, click **Internet of Things**, and then click **IoT Hub**.
2.  On the **IoT Hub** blade, in the **Name** box, type **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
3.  Click **Pricing** **and scale tier**, click **F1 Free**, and then click **Select**.
4.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
5.  In the **Location** list, select the same location as you used in Exercise 1, and then click **Create**.
6.  Wait until the IoT hub has deployed before continuing with the lab.
7.  Click **All Resources**, and then click **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
8.  On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **MESSAGING**, click **Endpoints**, and then in the **Built-in** **endpoints** section, click **Events**.
9.  In the **Properties** pane, under **Consumer groups**, in the box, type **patrolcars**, and in the next box, type **patrolcars2**.
10. In the **Properties** pane, click **Save**, and then close the Properties pane.
11. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt; - Endpoints** blade, click **Overview**.
12. On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, click the **Hostname**, and click the **Click to copy** button, to copy the string to the clipboard.
13. Switch to Notepad, press CTRL+END, and then press Enter.
14. Type **IoT hub settings**, and then press Enter.
15. On the **Edit** menu, click **Paste**, to store the hostname string.
16. Switch to the Azure portal, and on the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **SETTINGS**, click **Shared access policies**.
17. In the **Policy** list, click **iothubowner**.
18. In the **iothubowner** pane, next to the **Primary key**, click the **Click to copy** button, to copy the string to the clipboard.
19. Switch to Notepad, and press Enter.
20. On the **Edit** menu, click **Paste**, to store the connection string.
21. Switch to the Azure portal, and close the **iothubowner** pane.

#### Task 2: Create a new Stream Analytics job
1.  In the Azure portal, click **+ New**, click **Data + Analytics**, and then click **Stream Analytics job**.
2.  On the **New Stream Analytics Job** blade, in the **Job name** box, type **PatrolCarAnalytics**.
3.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
4.  In the **Location** list, select the same location as you used for the Data Lake Store, and then click **Create**.
5.  Wait until the Stream Analytics job has deployed before continuing with the lab.

#### Task 3: Configure Stream Analytics job inputs
1.  In the Azure portal, click **All resources**, and then click **PatrolCarAnalytics**.
2.  On the **PatrolCarAnalytics** blade, under **JOB TOPOLOGY**, click **Inputs**, and then click **+ Add**.
3.  On the **New input** blade, enter the following details:
    -   **Input alias**: PatrolCarDataFeed
    -   **Source Type**: Data stream
    -   **Source**: IoT hub
    -   **Import option**: Use IoT hub from current subscription
    -   **Consumer group**: patrolcars
4.  Leave all other settings at their defaults, and click **Create**.
5.  Wait until the input has been successfully created before continuing with the lab.
6.  On the **PatrolCarAnalytics - Inputs** blade, click **+ Add**.
7.  On the **New input** blade, enter the following details:
    -   **Input alias**: PatrolCarDataFeed2
    -   **Source Type**: Data stream
    -   **Source**: IoT hub
    -   **Import option**: Use IoT hub from current subscription
    -   **Consumer group**: patrolcars2
8.  Leave all other settings at their defaults, and click **Create**.
9.  Wait until the input has been successfully created before continuing with the lab.

#### Task 4: Configure Stream Analytics job outputs
1.  On the **PatrolCarAnalytics - Inputs** blade, under **JOB TOPOLOGY**, click **Outputs**, and then click **+ Add**.
2.  On the **New output** blade, enter the following details, and then click **Create**:
    -   **Output alias**: PatrolCarVisualData
    -   **Sink**: Power BI
    -   Click **Authorize**, and (if prompted) enter your Power BI credentials
    -   **Dataset Name**: PatrolCarData
    -   **Table Name**: PatrolCarData
3.  Wait until the output has been successfully created before continuing with the lab.
4.  On the **PatrolCarAnalytics - Outputs** blade, click **+ Add**.
5.  On the **New output** blade, enter the following details:
    -   **Output alias**: PatrolCarStoredData
    -   **Sink**: Data Lake Store
    -   Click **Authorize**, and (if prompted) enter your Power BI credentials
    -   **Path prefix pattern**: PatrolCarData/{date}/{time}
6.  Leave all other settings at their defaults, and click **Create**.
7.  Wait until the output has been successfully created before continuing with the lab.

#### Task 5: Configure the Stream Analytics job query
1.  On the **PatrolCarAnalytics - Outputs** blade, under **JOB TOPOLOGY**, click **Query**, and then replace the template query text with the following:

    ```
    SELECT
    CarID,LocationLatitude,LocationLongitude,System.TimeStamp AS Time
    INTO
    PatrolCarVisualData
    FROM
    PatrolCarDataFeed

    SELECT *
    INTO
    PatrolCarStoredData
    FROM
    PatrolCarDataFeed2
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab02\\ASAquery2.txt**.
2.  Click **Save**, and then click **Yes**.

#### Task 6: Start the Stream Analytics job
1.  On the **PatrolCarAnalytics - Query** blade, click **Overview**, and then click **Start**.
2.  On the **Start job** blade, click **Now**, and then click **Start**.
3.  Wait until the job has successfully started before continuing with the lab.

#### Task 7: Generate IoT hub data for processing with Stream Analytics
1.  Switch to Visual Studio.
2.  On the **File** menu, point to **Open**, and then click **Project/Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\PatrolCarDevice** folder, click **PatrolCarDevice.sln**, and then click **Open**.
4.  In Solution Explorer, double-click **App.config**.
5.  In App.config, in the **appSettings** section, in the **IoTHubConnectionString** and **IotHubUri** values, replace **YourIoTHub** with **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
6.  In App.config, in the **appSettings** section, in the **IoTHubConnectionString** value, replace the SharedAccessKey value **YourPrimaryKey** with the primary key you copied to **Config\_details.txt**.
7.  On the **Build** menu, click **Build Solution**.
8.  Verify that the app compiles successfully, and then click **Start**.
9.  Verify that the app opens a console window displaying the generated positions of patrol cars that are sent to the IoT hub.

#### Task 8: Visualize Stream Analytics output using Power BI
1.  In Internet Explorer, switch to the Power BI page.
2.  Click **My Workspace**, and then click **DataSets**. Verify that a streaming dataset named **PatrolCarData** is available (if this does not appear, wait a few minutes then refresh the page).
3.  Click **+ Create**, and then click **Report**.
4.  In the **Create report** dialog box, click **PatrolCarData**, and then click **Create**.
5.  In the **Fields** pane, select all the data fields.
6.  In the **Visualizations** pane, click **ArcGIS Maps for Power BI**.
7.  If the **Welcome to** **ArcGIS Maps for Power BI** page appears, click **OK**.
8.  Resize the map control to make it larger.
9.  The report shows a history of the movements of each patrol car.
10. Note that, as the report is generated, the data displayed is cumulative; you need to click **Refresh** to update the report.

#### Task 9: View Stream Analytics output in Azure Data Lake Store
1.  Switch to the Azure portal, click **All resources**, and then click **adls&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **Data Explorer**.
3.  On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **PatrolCarData**, and then click all the subfolders.
4.  Click the JSON file to view the contents in File Preview; verify that the data includes the fields you specified in your Stream Analytics query.
5.  Click **All resources**, and then click **PatrolCarAnalytics**.
6.  On the **PatrolCarAnalytics** blade, click **Stop**, and then click **Yes**.
7.  Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.

>**Result**: At the end of this exercise, you will have created a Data Lake Store, an IoT hub, and a new Stream Analytics job. You will then use Stream Analytics to process IoT hub data, and view the results in a Power BI report and in Data Lake Store.

## Exercise 3: Reconfigure a Stream Analytics job to send output through a Service Bus queue

#### Task 1: Create a Service Bus and queue
1.  In the Azure portal, click **+ New**, click **Enterprise Integration**, and then click **Service Bus**.
2.  On the **Create namespace** blade, in the **Name** box, type **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
3.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
4.  In the **Location** list, select the same location as you used for the Data Lake Store, and click **Create**.
5.  Wait until the Service Bus has deployed before continuing with the lab.
6.  Click **All resources**, and then click **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
7.  On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt;** blade, under **SETTINGS**, click **Shared access policies**, and then click **RootManageSharedAccessKey**.
8.  Next to the **PRIMARY KEY**, click the **Click to copy** button, to copy the primary key to the clipboard.
9.  Switch to Notepad.
10. In Notepad, press CTRL+END, and then press Enter.
11. Type **Service bus primary key**, and then press Enter.
12. On the **Edit** menu, click **Paste**, to store the primary key.
13. Switch to the Azure portal.
14. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt; - Shared access policies** blade, under **ENTITIES**, click **Queues**.
15. On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt; - Queues** blade, click **+ Queue**.
16. On the **Create queue** blade, in the **Name** box, type **LocationAlerts**.
17. Leave all other settings at their defaults, and click **Create**.
18. Wait until the queue has been successfully created before continuing with the lab.

#### Task 2: Reconfigure the IoT hub
1.  Click **All resources**, and then click **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **MESSAGING**, click **Endpoints**.
3.  On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt; - Endpoints** blade, under **Built-in endpoints**, click **Events**.
4.  In the **Properties** pane, under **Consumer groups**, in the box, type **patrolcars3**.
5.  In the **Properties** pane, click **Save**, and then close the Properties pane.

#### Task 3: Reconfigure the PatrolCarAnalytics Stream Analytics job
1.  Click **All resources**, and then click **PatrolCarAnalytics**.
2.  On the **PatrolCarAnalytics** blade, under **JOB TOPOLOGY**, click **Inputs**, and then click **+ Add**.
3.  On the **New input** blade, enter the following details:
    -   **Input alias**: PatrolCarDataFeed3
    -   **Source Type**: Data stream
    -   **Source**: IoT hub
    -   **Import option**: Use IoT hub from current subscription
    -   **Consumer group**: patrolcars3
4.  Leave all other settings at their defaults, and click **Create**.
5.  Wait until the input has been successfully created before continuing with the lab.
6.  On the **PatrolCarAnalytics - Inputs** blade, under **JOB TOPOLOGY**, click **Outputs**, and then click **+ Add**.
7.  On the **New output** blade, enter the following details:
    -   **Output alias**: PatrolCarLocationAlerts
    -   **Sink**: Service bus Queue
    -   **Import option**: Use queue from current subscription
8.  Leave all other settings at their defaults, and click **Create**.
9.  Wait until the output has been successfully created before continuing with the lab.
10.  On the **PatrolCarAnalytics - Outputs** blade, under **JOB TOPOLOGY**, click **Query**, and then add the following to the end of the existing query:
    
    ```
    SELECT
    CarID,CarNum,LocationLatitude,LocationLongitude,Speed
    INTO
    PatrolCarLocationAlerts
    FROM
    PatrolCarDataFeed3
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab02\\ASAquery3.txt**.
11.  Click **Save**, and then click **Yes**.

#### Task 4: Start the Stream Analytics job
1.  On the **PatrolCarAnalytics - Query** blade, click **Overview**, and then click **Start**.
2.  On the **Start job** blade, click **Now**, and then click **Start**.
3.  Wait until the job has successfully started before continuing with the lab.

#### Task 5: Prepare an application to receive Stream Analytics data using a Service Bus
1.  On the Start menu, type **Visual Studio 2017**, and then press Enter.
2.  On the **File** menu, point to **Open**, and then click **Project/Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\LocationAlerts** folder, click **LocationAlerts.sln**, and click **Open**; this project displays the movements of patrol cars that it receives from the queue.
4.  In Solution Explorer, double-click **ConfigSettings.txt**.
5.  In ConfigSettings.txt, replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
6.  In ConfigSettings.txt, replace **YourPrimaryKey** with the primary key from the service bus connection string you copied to Notepad in Task 1, Step 13.
7.  On the **Build** menu, click **Build Solution**.
8.  Verify that the app compiles successfully, and then click **Local Machine** (Start).
9.  Verify that the app displays a map (of London), but not the positions of any patrol cars yet.

#### Task 6: Generate IoT hub data for processing with Stream Analytics
1.  Switch to your first instance of Visual Studio.
2.  Click **Start** to run the **PatrolCarDevice** app, to start generating patrol car movements.
3.  Switch to the map.
4.  Verify that, after a few seconds, the locations of patrol cars start appearing on the map—and that these positions slowly change as patrol cars are driven around. You might have to zoom out to see all the patrol cars.
5.  Allow the system to run for a while, so that you see the patrol car movements.
6.  Switch to the Azure portal.
7.  Click **All resources**, and then click **PatrolCarAnalytics**.
8.  On the **PatrolCarAnalytics** blade, click **Stop**, and then click **Yes**.
9.  Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.
10. Close the map window.
11. Close both instances of Visual Studio.

>**Result**: At the end of this exercise, you will have created an Azure Service Bus, reconfigured an existing IoT hub, and an existing Stream Analytics job. You will then use Stream Analytics to process IoT hub data and to send results to the Service Bus. Finally, you will use a custom Visual Studio application to view the output of the Service Bus.

## Exercise 4: Reconfigure a Stream Analytics job to process both event hub and static file data

#### Task 1: Create a Blob storage account for holding stolen vehicle data
1.  In the Azure portal, click **+ New**, click **Storage**, and then click **Storage account - blob, file, table, queue**.
2.  On the **Storage account - blob, file, table, queue** blade, click **Create**.
3.  On the **Create storage account** blade, in the **Name** box, type **datastore&lt;_your name_&gt;&lt;_date_&gt;**.
4.  Under **Resource group**, click **Use existing**, and then click **CamerasRG**.
5.  In the **Location** list, select the same location as you used for the Data Lake Store.
6.  Leave all other details at their defaults, and click **Create**.
7.  Wait until the storage account has been successfully created before continuing with the lab.
8.  Click **All resources**, and then click **datastore&lt;_your name_&gt;&lt;_date_&gt;**.
9.  On the **datastore&lt;_your name_&gt;&lt;_date_&gt;** blade, under **BLOB SERVICE**, click **Containers**.
10. On the **datastore&lt;_your name_&gt;&lt;_date_&gt; - Containers** blade, click **+ Container**.
11. In the **New container** dialog box, in the **Name** box, type **stolenvehicledata**, and then click **OK**.

#### Task 2: Examine the StolenVehiclesReport.csv file
1.  On the taskbar, click **File Explorer**.
2.  In File Explorer, go to **E:\\Labfiles\\Lab02**, and then double-click **StolenVehiclesReport.csv**.
3.  Verify that this file contains the registration number, date stolen, and date recovered for stolen vehicles; if a vehicle is still missing, the date recovered is empty.
4.  Close Microsoft Excel, without saving any changes.

#### Task 3: Use Azure Storage Explorer to upload a StolenVehiclesReport.csv to the Blob storage container
1.  On the Start menu, type **Microsoft Azure Storage Explorer**, and then press Enter.
2.  In the **Connect to Azure Storage** dialog box, ensure that **Add an Azure Account** is selected, and then click **Sign in**.
3.  In the **Sign in to your account** dialog box, enter the credentials of the Microsoft account that is associated with your Azure Learning Pass subscription, and then click **Sign in**.
4.  Select your Azure Learning Pass subscription check box, and then click **Apply**.
5.  Under your Azure Learning Pass subscription, under **Storage Accounts**, expand **datastore&lt;_your name_&gt;&lt;_date_&gt;**.
6.  Expand **Blob Containers**, and then click **stolenvehicledata**.
7.  In the right pane, click **Upload**, and then click **Upload Files**.
8.  In the **Upload files** dialog box, click the ellipsis (**...**).
9.  In the **Select files to upload** dialog box, go to **E:\\Labfiles\\Lab02**, click **StolenVehiclesReport.csv**, and then click **Open**.
10. In the **Upload files** dialog box, click **Upload**.
11. When the upload has completed, close Microsoft Azure Storage Explorer.

#### Task 4: Update the event hub and add two more consumer groups
1.  In Microsoft Azure, click **All resources**, and then click **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;** blade, under **ENTITIES**, click **Event Hubs**, and then click **traffic**.
3.  On the **traffic** blade, click **+ Consumer Group**.
4.  On the **Create consumer group** blade, in the **Name** box, type **stolenvehiclefeed1**, and then click **Create**.
5.  On the **traffic** blade, click **+ Consumer Group**.
6.  On the **Create consumer group** blade, in the **Name** box, type **stolenvehiclefeed2**, and then click **Create**.

#### Task 5: Reconfigure the TrafficAnalytics Stream Analytics job inputs
1.  Click **All resources**, and then click **TrafficAnalytics**.
2.  On the **TrafficAnalytics** blade, under **JOB TOPOLOGY**, click **Inputs**, and then click **+ Add**.
3.  On the **New input** blade, enter the following details:
    -   **Input alias**: StolenVehicleData
    -   **Source Type**: Reference data
    -   **Import option**: Use Blob storage from current subscription
    -   **Path pattern**: StolenVehiclesReport.csv
    -   **Event serialization format**: CSV
4.  Leave all other settings at their defaults, and click **Create**.
5.  Wait until the input has been successfully created before continuing with the lab.
6.  On the **TrafficAnalytics - Inputs** blade, click **+ Add**.
7.  On the **New input** blade, enter the following details:
    -   **Input alias**: StolenVehicleFeed1
    -   **Source Type**: Data stream
    -   **Source**: Event hub
    -   **Import option**: Use event hub from current subscription
    -   **Event hub consumer group**: stolenvehiclefeed1
8.  Leave all other settings at their defaults, and click **Create**.
9.  Wait until the input has been successfully created before continuing with the lab.
10.  On the **TrafficAnalytics - Inputs** blade, click **+ Add**.
11.  On the **New input** blade, enter the following details:
    -   **Input alias**: StolenVehicleFeed2
    -   **Source Type**: Data stream
    -   **Source**: Event hub
    -   **Import option**: Use event hub from current subscription
    -   **Event hub consumer group**: stolenvehiclefeed2
12.  Leave all other settings at their defaults, and click **Create**.
13.  Wait until the input has been successfully created before continuing with the lab.

#### Task 6: Reconfigure the TrafficAnalytics Azure Stream Analytics job outputs
1.  On the **TrafficAnalytics - Inputs** blade, under **JOB TOPOLOGY**, click **Outputs**, and then click **+ Add**.
2.  On the **New output** blade, enter the following details, and then click **Create**:
    -   **Output alias**: StolenCarAlerts
    -   **Sink**: Power BI
    -   Click **Authorize**, and (if prompted) enter your Power BI credentials
    -   **Dataset name**: StolenCarAlerts
    -   **Table name**: StolenCarAlerts
3.  Wait until the output has been successfully created before continuing with the lab.
4.  On the **TrafficAnalytics - Outputs** blade, click **+ Add**.
5.  On the **New output** blade, enter the following details:
    -   **Output alias**: StolenCarObservations
    -   **Sink**: Data Lake Store
    -   Click **Authorize**, and (if prompted) enter your Azure credentials
    -   **Path prefix pattern**: StolenCarObservations/{date}/{time}
6.  Leave all other settings at their defaults, and click **Create**.
7.  Wait until the output has been successfully created before continuing with the lab.

#### Task 7: Reconfigure the TrafficAnalytics Stream Analytics job query
1.  On the **TrafficAnalytics - Outputs** blade, under **JOB TOPOLOGY**, click **Query**, and then add the following to the end of the existing query:

    ```
    SELECT
    C.VehicleRegistration,C.LocationLatitude,C.LocationLongitude,C.Time
    INTO
    StolenCarAlerts
    FROM
    StolenVehicleFeed1 C
    JOIN
    StolenVehicleData V
    ON
    C.VehicleRegistration = V.Vehicle
    WHERE
    V.Recovered = ""

    SELECT
    C.VehicleRegistration,C.LocationLatitude,C.LocationLongitude,C.Time
    INTO
    StolenCarObservations
    FROM
    StolenVehicleFeed2 C
    JOIN
    StolenVehicleData V
    ON
    C.VehicleRegistration = V.Vehicle
    WHERE
    V.Recovered = ""
    ```
You copy the preceding commands from **E:\\Labfiles\\Lab02\\ASAquery4.txt**.
2.  Click **Save**, and then click **Yes**.

#### Task 8: Start the TrafficAnalytics Stream Analytics job
1.  On the **TrafficAnalytics - Query** blade, under **CONFIGURE**, click **Scale**.
2.  On the **TrafficAnalytics - Scale** blade, in the **Streaming units** box, type **12**, click **Save**, and then click **Yes**.
3.  On the **TrafficAnalytics - Scale** blade, click **Overview**, and then click **Start**.
4.  On the **Start job** blade, click **Now**, and then click **Start**.
5.  Wait until the job has successfully started before continuing with the lab.

#### Task 9: Generate event hub data for processing with Stream Analytics
1.  On the Start menu, type **Visual Studio 2017**, and then press Enter.
2.  On the **File** menu, point to **Open**, and then click **Project/Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\SpeedCameraDevice** folder, click **SpeedCameraDevice.sln**, and then click **Open**.
4.  Click **Start**.
5.  Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.

#### Task 10: Visualize Stream Analytics output using Power BI
1.  In Internet Explorer, switch to the Power BI tab.
2.  Click **My Workspace**, and then click **DataSets**.
3.  If the **Unsaved changes** dialog box appears, click **Don’t save**.
4.  Verify that a streaming dataset named **StolenCarAlerts** is available (if this does not appear, wait a few minutes, and then refresh the page).
5.  Click **+ Create**, and then click **Dashboard**.
6.  In the **Create dashboard** dialog box, in the **Dashboard** **name** box, type **Stolen Vehicle Alerts**, and then click **Create**.
7.  Click the **+ Add** **tile**.
8.  In the **Add tile** pane, click **CUSTOM STREAMING DATA**, and then click **Next**.
9.  In the **Add a custom streaming data tile** pane, click **StolenCarAlerts**, and then click **Next**.
10. In the **Add a custom streaming data tile** pane, in the **Visualization Type** list, click **Clustered column chart**.
11. Under **Axis**, click **Add value**, and then select **vehicleregistration**.
12. Under **Legend**, click **Add value**, and then select **time**.
13. Under **Value**, click **Add value**, and then select **locationlatitude**.
14. Under **Tooltips**, click **Add value**, and then select **locationlongitude**.
15. Under **Time window to display**, select **1 Seconds**, and then click **Next**.
16. In the **Tile details** pane, in the title box, type **Vehicles reported stolen and detected by cameras**, and then click **Apply**.
17. Leave the tile to display for a few minutes; note that it is updated every 1 seconds; it displays the registration number of a vehicle, together with the date, time, and location, if it is marked as stolen.
18. Hover the mouse over the chart, and verify that it shows vehicle registration, date/time, and location.

#### Task 11: View Stream Analytics output in Data Lake Store
1.  Switch to the Azure portal, click **All resources**, and then click **adls_&lt;your name&gt;&lt;date&gt;_**.
2.  On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **Data Explorer**.
3.  On the **adls&lt;_your name_&gt;&lt;_date_&gt;** blade, click **StolenCarObservations**, and then click all the subfolders.
4.  Click the log file to view the contents in File Preview; verify that the data includes the fields you specified in your Azure Stream Analytics query.
5.  Click **All resources**, and then click **TrafficAnalytics**.
6.  On the **TrafficAnalytics** blade, click **Stop**, and then click **Yes**.
7.  Switch to the Visual Studio app window (where the data is being generated), and press Enter to stop the app.

>**Result**: At the end of this exercise, you will have uploaded data to a new Blob storage container, updated your event hub with new consumer groups, and reconfigured your TrafficAnalytics Azure Stream Analytics job to use these new inputs. You will then use Stream Analytics to process the event hubs data, and view the results in a Power BI dashboard, and in Data Lake Store.

## Exercise 5: Use multiple Stream Analytics jobs to process event hub, IoT hub and static file data, and output results using a Service Bus and custom application

#### Task 1: Create a new Service Bus topic and add a subscription
1.  In the Azure portal, click **All resources**, and then click **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt;** blade, under **ENTITIES**, click **Topics**, and then click **+ Topic**.
3.  On the **Create topic** blade, in the **Name** box, type **stolencaralerts**, and then click **Create**.
4.  On the **locationalerts&lt;_your name_&gt;&lt;_date_&gt; - Topics** blade, click **stolencaralerts**, and then click **+ Subscription**.
5.  On the **Create subscription** blade, in the **Name** box, type **stolen**, and then click **Create**.

#### Task 2: Reconfigure the IoT hub and add a new consumer group
1.  Click **All resources**, and then click **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **patrolcars&lt;_your name_&gt;&lt;_date_&gt;** blade, under **MESSAGING**, click **Endpoints**, and then click **Events**.
3.  In the **Properties** pane, under **Consumer groups**, in the box, type **patrolcars4**.
4.  In the **Properties** pane, click **Save**, and then close the Properties pane.

#### Task 3: Reconfigure the event hub and add a new consumer group
1.  Click **All resources**, and then click **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;**.
2.  On the **camerafeeds&lt;_your name_&gt;&lt;_date_&gt;** blade, under **ENTITIES**, click **Event Hubs**, and then click **traffic**.
3.  On the **traffic** blade, click **+ Consumer Group**.
4.  On the **Create consumer group** blade, in the **Name** box, type **stolenvehiclefeed3**, and then click **Create**.

#### Task 4: Reconfigure the TrafficAnalytics Azure Stream Analytics job inputs
1.  Click **All resources**, and then click **TrafficAnalytics**.
2.  On the **TrafficAnalytics** blade, under **JOB TOPOLOGY**, click **Inputs**, and then click **+ Add**.
3.  On the **New input** blade, enter the following details:
    -   **Input alias**: PatrolCarLocation
    -   **Source Type**: Data stream
    -   **Source**: IoT hub
    -   **Import option**: Use IoT hub from current subscription
    -   **Consumer group**: patrolcars4
4.  Leave all other settings at their defaults, and click **Create**.
5.  Wait until the input has been successfully created before continuing with the lab.
6.  On the **TrafficAnalytics - Inputs** blade, click **+ Add**.
7.  On the **New input** blade, enter the following details:
    -   **Input alias**: StolenVehicleFeed3
    -   **Source Type**: Data stream
    -   **Source**: Event hub
    -   **Import option**: Use event hub from current subscription
    -   **Event hub consumer group**: stolenvehiclefeed3
8.  Leave all other settings at their defaults, and click **Create**.
9.  Wait until the input has been successfully created before continuing with the lab.

#### Task 5: Reconfigure the TrafficAnalytics Stream Analytics job outputs
1.  On the **TrafficAnalytics - Inputs** blade, under **JOB TOPOLOGY**, click **Outputs**, and then click **+ Add**.
2.  On the **New output** blade, enter the following details:
    -   **Output alias**: StolenVehicleAlerts
    -   **Sink**: Service bus Topic
3.  Leave all other settings at their defaults, and click **Create**.
4.  Wait until the output has been successfully created before continuing with the lab.

#### Task 6: Reconfigure the TrafficAnalytics Stream Analytics job query
1.  On the **TrafficAnalytics - Outputs** blade, under **JOB TOPOLOGY**, click **Query**, and then add the following to the end of the existing query:

    ```
    SELECT
    P.CarID,V.Vehicle,C.LocationLatitude,C.LocationLongitude
    INTO
    StolenVehicleAlerts
    FROM
    StolenVehicleFeed3 C
    JOIN
    StolenVehicleData V
    ON
    C.VehicleRegistration = V.Vehicle
    JOIN
    PatrolCarLocation P
    ON
    ST_DISTANCE(CreatePoint(C.LocationLatitude,C.LocationLongitude),CreatePoint(P.LocationLatitude,P.LocationLongitude)) < 8000
    AND
    DATEDIFF(second,P,C) BETWEEN 0 AND 10
    WHERE
    V.Recovered = ""
    ```

You copy the preceding commands from **E:\\Labfiles\\Lab02\\ASAquery5.txt**.
2.  Click **Save**, and then click **Yes**.

#### Task 7: Start the TrafficAnalytics Azure and PatrolCarAnalytics Stream Analytics jobs
1.  On the **TrafficAnalytics - Query** blade, click **Overview**, and then click **Start**.
2.  On the **Start job** blade, click **Now**, and then click **Start**.
3.  Click **All resources**, and then click **PatrolCarAnalytics**.
4.  On the **PatrolCarAnalytics** blade, click **Start**.
5.  On the **Start job** blade, click **Now**, and then click **Start**.
6.  Wait until the jobs have successfully started before continuing with the lab.

#### Task 8: Generate event hub and IoT hub data for processing with Stream Analytics
1.  Switch to the Visual Studio instance that has the **SpeedCameraDevice** project open.
2.  Click **Start**.
3.  Verify that the app opens a console window displaying generated speed camera data that is being sent to the event hub.
4.  On the Start menu, type **Visual Studio 2017**, and then press Enter, to start a new instance of Visual Studio.
5.  On the **Get Started** page, click **Open Project / Solution**.
6.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\PatrolCarDevice2** folder, click **PatrolCarDevice.sln**, and then click **Open**; note that this is a modified version of the app you worked with in Exercise 2 and 3.
7.  In Solution Explorer, double-click **App.config**.
8.  In App.config, in the **appSettings** section, in the **ServiceBusConnectionString** key, replace **YourServiceBusName** with **locationalerts&lt;_your name_&gt;&lt;_date_&gt;**, and replace **YourServiceBusPrimaryKey** with the primary key you copied to **Config\_details.txt**.
9.  In App.config, in the **appSettings** section, in the **IoTHubConnectionString** and **IotHubUri** keys, replace **YourNamespace** with **patrolcars&lt;_your name_&gt;&lt;_date_&gt;**.
10. In App.config, in the **appSettings** section, in the **IoTHubConnectionString** key, replace the SharedAccessKey value **YourIoTHubPrimaryKey** with the SharedAccessKey from the IoT hub connection string you copied to **Config\_details.txt**.
11. On the **Build** menu, click **Build Solution**.
12. Verify that the app compiles successfully, and then click **Start**.
13. Verify that the app opens a console window displaying the generated positions of patrol cars that are being sent to the IoT hub.

#### Task 9: Start an application to receive Stream Analytics data using a Service Bus
1.  On the Start menu, type **Visual Studio 2017**, and then press Enter, to start a new instance of Visual Studio.
2.  On the **Get Started** page, click **Open Project / Solution**.
3.  In the **Open Project** dialog box, go to the **E:\\Labfiles\\Lab02\\LocationAlerts** folder, click **LocationAlerts.sln**, and click **Open**.
4.  Click **Local Machine** (Start).
5.  Verify that the app displays a map (of London), and starts to show the positions of patrol cars.
6.  Let the system run for a few minutes, to give it time to detect some stolen vehicles, and then observe the fun!
7.  Note that the **PatrolCarDevice** project reports messages when a patrol car is dispatched to chase a stolen vehicle. You should also see the location of the patrol car change to move to the location reported for the stolen vehicle in the **LocationAlerts** app. Arrange your desktop so that you see the Patrol Car output and map side by side. If you do not see all the patrol cars, zoom out of the map.
8.  At the end of the exercise, keep the apps and the Stream Analytics jobs running, ready for the final exercise in this lab.
9.  Close Notepad, and save any changes.

>**Result**: At the end of this exercise, you will have:
-   Created a new Service Bus topic, and added a subscription to this topic.
-   Reconfigured the IoT and event hubs, and added a new consumer group to each hub.
-   Reconfigured the TrafficAnalytics Azure Stream Analytics job to use these new inputs, and to use the new Service Bus topic as a job output.
-   Updated the job query to send data to the Service Bus topic, by using a Visual Studio application.

## Exercise 6: Use the Azure portal and Azure PowerShell to manage and scale Stream Analytics jobs

#### Task 1: Add a monitoring alert to a Stream Analytics job
1.  In the Azure portal, click **All resources**, and then click the **PatrolCarAnalytics**.
2.  On the **PatrolCarAnalytics** blade, on the **Overview** page, scroll down to view the Monitoring graph.
3.  Note that, for this job, the number of input and output events are typically the same, and then click the graph.
4.  On the **Metric** blade, click **+ Add alert**.
5.  On the **Add an alert rule** blade, in the **Name** box, type **Streaming unit utilization**.
6.  In the **Metric** list, click **SU % Utilization**.
7.  Note the current range of utilization.
8.  In the **Condition** list, click **greater than**.
9.  In the **Threshold** box, type **n**, where "n" is less than the maximum utilization you noted earlier; for example, if you noted a maximum of 60%, set the threshold to 50%.
10. Leave all the other settings at their defaults, and click **OK**.
11. On the **Metric** blade, within five minutes, your alert should be triggered, and appear in the **Alerts** section.
12. Close the Metric blade.

#### Task 2: Use the Azure portal to scale up a Stream Analytics job
1.  On the **PatrolCarAnalytics** blade, click **Overview**, click **Stop**, and then click **Yes**.
2.  Wait until the job has successfully stopped before continuing with the lab.
3.  Under **CONFIGURE**, click **Scale**.
4.  On the **PatrolCarAnalytics - Scale** blade, drag the slider to **18**, click **Save**, and then click **Yes**.
5.  On the **PatrolCarAnalytics - Scale** blade, click **Overview**, and then click **Start**.
6.  On the **Start job** blade, click **Now**, and then click **Start**.
7.  Wait until the job has successfully started before continuing with the lab.
8.  On the **PatrolCarAnalytics** blade, click the **Monitoring** graph.
9.  On the **Metric** blade, click the **Streaming** **unit utilization** alert.
10. On the **Edit Rule** blade, note that the **SU % Utilization** is lower than before, because more streaming units have been deployed.
11. Close the Edit Rule blade.

#### Task 3: Use Azure PowerShell to stop a Stream Analytics job
1.  On the Start menu, type **Windows** **PowerShell ISE**, right-click **Windows** **PowerShell ISE**, and then click **Run as administrator**.
2.  In the **User Account Control** dialog box, click **Yes**.
3.  Note that you can copy all the following PowerShell commands from **E:\\Labfiles\\Lab02\\ASAPowerShell.txt**.
4.  In the script area, type the following commands, and then click **Run Script**:

    ```
    Login-AzureRmAccount
    Get-AzureRMStreamAnalyticsJob -NoExpand
    ```
5.  In the **Sign in to your account** dialog box, enter the details of the Microsoft account that is associated with your Azure Learning Pass subscription, and then click **Sign in**.
6.  The results display information about the two Stream Analytics jobs.
7.  In the script area, type the following command, highlight it, and then click **Run Selection**:
    ```
    Stop-AzureRMStreamAnalyticsJob -ResourceGroupName CamerasRG –Name PatrolCarAnalytics
    ```
8.  In the script area, type the following command, highlight it, and then click **Run Selection**:
    ```
    (Get-AzureRmStreamAnalyticsJob -ResourceGroupName CamerasRG -Name PatrolCarAnalytics).JobState
    ```
9.  Verify that the job has stopped.
10.  On the toolbar, click **Save**.
11. In the **Save As** dialog box, go to **E:\\Labfiles\\Lab02**, in the **File name** box, type **ShutdownASAjob.ps1**, and then click **Save**.

#### Task 4: Use Azure PowerShell to scale down and restart a Stream Analytics job
1.  In File Explorer, go to **E:\\Labfiles\\Lab02**, right-click **patrolcaranalytics.json**, point to **Open with**, and then click **Choose another app**.
2.  In the **How do you want to open this file?** dialog box, click **More apps**, click **Microsoft Visual Studio Version Selector**, and then click **OK** to open the file in Visual Studio.
3.  This file contains the JSON format code for the Stream Analytics job query, and the scaling information; note the line near the end of the file that specifies the number of StreamingUnits to use (1).
4.  Close patrolcaranalytics.json.
5.  Switch to the PowerShell ISE.
6.  On the toolbar, click **New**.
7.  In the script area, type the following commands:
    ```
    New-AzureRmStreamAnalyticsTransformation -File E:\Labfiles\Lab02\patrolcaranalytics.json -JobName PatrolCarAnalytics -ResourceGroupName CamerasRG -Name Transformation -Force

    Start-AzureRMStreamAnalyticsJob -ResourceGroupName CamerasRG –Name PatrolCarAnalytics

    (Get-AzureRmStreamAnalyticsJob -ResourceGroupName CamerasRG -Name PatrolCarAnalytics).JobState
    ```
8.  On the toolbar, click **Save**.
9.  In the **Save As** dialog box, go to **E:\\Labfiles\\Lab02**, in the **File name** box, type **ScaleUpAndStartASAjob.ps1**, and then click **Save**.
10.  On the toolbar, click **Run Script**.
11.  Wait for the script to run—this might take several minutes.
12.  Switch to the Azure portal.
13.  On the **PatrolCarAnalytics** blade, under **CONFIGURE**, click **Scale**.
14.  On the **Scale** blade, verify that the number of streaming units has been reset to 1.

#### Task 5: Use job diagrams to visualize Stream Analytics job configurations
1.  On the **PatrolCarAnalytics - Scale** blade, under **SUPPORT + TROUBLESHOOTING**, click **Job diagram**.
2.  Note the inputs from the IoT hub, the queries, and the outputs to the Service Bus queue, Data Lake Store, and Power BI.
3.  Click any of the boxes to get more information.
4.  Close the job diagram.
5.  Repeat the preceding steps for the TrafficAnalytics Stream Analytics job; note that, for this job, the diagram is more complex because there are more inputs, outputs, and queries, including data merging.
6.  Close the job diagram.

#### Task 6:  Lab closedown
1.  On the **TrafficAnalytics** blade, click **Overview**, click **Stop**, and then click **Yes**.
2.  Click **All resources**, and then click **PatrolCarAnalytics**.
3.  On the **PatrolCarAnalytics** blade, click **Stop**, and then click **Yes**.
4.  Close the Visual Studio map window, to stop the LocationAlerts app.
5.  In the Visual Studio app window for **PatrolCarDevice**, press Enter to stop the app.
6.  In the Visual Studio app window for **SpeedCameraDevice**, press Enter to stop the app.
7.  Close the PowerShell ISE.
8.  Close all instances of Visual Studio 2017.
9.  Do not remove the Azure resources (resource group, Stream Analytics jobs, event hub, IoT hub, and storage); these resources will be used in Lab 3.

>**Result**: At the end of this exercise, you will have:
-   Added a monitoring alert to a Stream Analytics job.
-   Used the Azure portal to scale up a Stream Analytics job.
-   Used Azure PowerShell to stop a Stream Analytics job.
-   Used Azure PowerShell to scale down and restart a Stream Analytics job.
-   Used job diagrams to visualize Stream Analytics job configurations.

©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
